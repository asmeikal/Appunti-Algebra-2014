
\begin{center}
\indent
\textit{Gruppi, anelli, campi. In particolare, anello degli interi modulo $m$ intero, anello dei polinomi.}
\end{center}

\section{Strutture algebriche con un'operazione}

Una struttura algebrica \`e una coppia $(A, \cdot)$ dove A \`e un'insieme e $\cdot$ \`e un'operazione $\cdot : A \times A \to A$. Ad esempio $(\mathbb{N}, +)$ \`e una struttura algebrica.

Le operazioni sono funzioni definite su prodotti cartesiani a valori in un insieme. Un'operazione binaria \`e definita sul prodotto cartesiano fra due insiemi.

Riprendendo la composizione, dati tre insiemi $A, B, C$, $B^A$ \`e l'insieme delle funzioni da $A$ in $B$, $C^B$ \`e l'insieme delle funzioni da $B$ in $C$. La composizione $\circ$ \`e un'operazione definita sul prodotto cartesiano degli insiemi $B^A \times C^B \to C^A$.

Posso rappresentare un'operazione come funzione $(\circ \left( f, g \right))$ o inserendo l'operatore fra i due operandi $ (g \circ f) $.
\begin{gather*}
f: \mathbb{R} \times \mathbb{R} \to \mathbb{R} ; \
f(x,y) = \sqrt{2} \cdot x + y \\
g: \mathbb{R} \to \mathbb{R} \times \mathbb{R} ; \
g(z) = (0,z) \\
g \circ f : \mathbb{R} \times \mathbb{R} \to \mathbb{R} \times \mathbb{R} \\
(x,y) \xrightarrow{f} \sqrt{2} \cdot x + y = z \xrightarrow{g} \left( 0, \sqrt{2}x + y \right) \\
f \circ g : \mathbb{R} \to \mathbb{R} \\
z \xrightarrow{g} (0,z) \xrightarrow{f} \sqrt{2} \cdot 0 + z = z
\end{gather*}

Una struttura algebrica \`e un'insieme su cui \`e definita un'operazione che prende due elementi di quell'insieme e gliene associa un terzo.

Le strutture vengono classificate in base alle loro propriet\`a:
\begin{description}
    \item[Propriet\`a associativa\label{itm:strutture_associativa}] $\forall \ a, b, c \in A : a \cdot (b \cdot c) = (a \cdot b) \cdot c$
    \item[Elemento neutro\label{itm:strutture_neutro}] Esistenza di un'elemento neutro, o elemento identit\`a. $1 \in A : \forall \ a \in A , a \cdot 1 = a = 1 \cdot a$
    \item[Propriet\`a commutativa\label{itm:strutture_commutativa}] $ \forall a, b \in A , a \cdot b = b \cdot a $. In una struttura algebrica commutativa in genere l'identit\`a si indica con 0.
    \item[Inverso\label{itm:strutture_inverso}] Esistenza dell'inverso. $ \forall a \in A \ \exists \ b \in A $ t.c. $a \cdot b = 1 = b \cdot a $.
\end{description}

\subsection{Classificazione delle strutture algebriche con una operazione}

Per essere studiabile, una struttura algebrica deve essere quantomeno associativa.

\begin{description}
    \item[Semigruppo] struttura algebrica associativa.
    \item[Monoide] struttura algebrica associativa con elemento identit\`a.
    \item[Gruppo] struttura algebrica associativa con elemento identit\`a e con inverso (ossia, monoide con inverso).
    \item[Gruppo abeliano] struttura algebrica che presenta tutte e quattro le propriet\`a: associativa, elemento neutro, commutativa, inverso.
\end{description}

La struttura algebrica $\left( \mathbb{N}, + \right)$ \`e un monoide commutativo. Anche $\left( \mathbb{N}, \cdot \right)$ \`e un monoide commutativo. $\left( \mathbb{Z}, + \right)$ \`e un gruppo perch\`e esiste l'inverso. $\left( \mathbb{Z}, \cdot \right)$ \`e un monoide, perch\'e non ha l'inverso.

\subsection{Gruppo simmetrico}

\begin{defn}[Gruppo simmetrico]
Il prototipo di tutti i gruppi \`e il gruppo simmetrico su $n$ elementi, il cui insieme \`e indicato con $S_n$. Prendiamo un insieme $E = \left\{ e_1, \dots, e_n \right\}$.
\[
S_n = \left\{ f : E \to E \text{ t.c. $f$ \`e biunivoca} \right\}
\]
Quindi $S_n$ \`e l'insieme di tutte le permutazioni degli elementi di $E$. Il gruppo simmetrico \`e definito sull'insieme $S_n$ e l'operazione \`e la composizione: $\left( S_n, \circ \right)$.
\begin{enumerate}
    \item $f \circ \left( g \circ h \right) = \left( f \circ g \right) \circ h$ 
    \item L'unit\`a \`e la funzione identica (o identit\`a) $i_E : E \to E$ tale che $\forall \ e \in E $ $i_E(e) = e$. $f \circ i_E = f = i_E \circ f$ 
    \item Una funzione biunivoca $f$ ha una funzione inversa $g$. $g : E \to E $ t.c. $ g(f(e)) = e$.
\end{enumerate}
\end{defn}

Una funzione $f : E \to E $ iniettiva su un insieme finito $E$ \`e necessariamente suriettiva e quindi biunivoca. Un insieme \`e finito se non pu\`o essere messo in corrispondenza biunivoca con un suo sottoinsieme proprio.

% \subsection{Punto di vista dell'occupazione}

% $f : \left \{ 1, \dots, 6 \right \} \to \left \{ 1, \dots, 6 \right \}$. Penso il dominio come degli oggetti. Il codominio come dei ``cassetti''. La funzione \`e un modo di mettere gli oggetti del dominio nei ``cassetti''.

% \begin{tabular}{cccccc}
% 1 & 2 & 3 & 4 & 5 & 6 \\
% 2 & 3 & 5  &1 & 6 & 4
% \end{tabular}
% \`E un'occupazione.

% \begin{tabular}{cccccc}
% 1 & 2 & 3 & 4 & 5 & 6 \\
% 6 & 6 & 3 & 5 & 5 & 5
% \end{tabular}
% Non \`e un'occupazione.


\section{Monoidi}

Un monoide $(M, \cdot)$ \`e una struttura algebrica con un'operazione $\cdot : M \times M \to M$ tale che:
\begin{description}
    \item[1M] L'operazione $\cdot$ \`e associativa;
    \item[2M] $\exists \ 1_M $ t.c. $ \forall \ a \in M$ $ 1_M \cdot a = a = a \cdot 1_M$, ossia esiste l'elemento identit\`a. 
\end{description}

Un sottomonoide $(S, \cdot)$ con $S \subseteq M$ \`e un monoide in cui esiste l'operazione $\cdot : S \times S \to S$, ossia $S$ \`e chiuso, cio\`e $\forall s, s' \in S $, $s \cdot s' \in S$ e $1_M \in S$.

Ad esempio, considerando $(\mathbb{N}, +)$, $(P, +)$ con $P = \{ m \in \mathbb{N} : \exists \ k $ t.c. $m = 2k \}$ \`e un sottomonoide di $(\mathbb{N},+)$ perch\`e la somma di due pari \`e pari e lo 0 appartiene ai pari.

$k \mathbb{N} = \{ m \in \mathbb{N} : \exists \ t \in \mathbb{N} $ t.c. $ m = k t\}$ \`e la ``versione generale'' dell'insieme dei numeri pari.

Considerando $(\mathbb{N}, \cdot)$ e l'elemento neutro 1, i pari non sono un sottomonoide perch\'e non hanno l'elemento neutro, ma i dispari s\`i.

\subsection{Morfismi di monoidi}

\begin{defn}
Dati i monoidi $(M, \cdot)$ e $(A, \ast)$, un morfismo di monoidi \`e un'applicazione $f : M \to A$ che conserva le strutture, ossia tale che $\forall \ x,y \in M $ ho che $f(x \cdot y) = f(x) \ast f(y)$. Inoltre, $f(1_M) = 1_A$.
\end{defn}

\subsection{Teorema di omomorfismo per i monoidi\label{omomorfismo_monoidi}}

\begin{prop}
Sia $f : (M, \cdot) \to (A, \ast)$ un morfismo di monoidi, $f$ definisce una relazione di equivalenza $\varepsilon_f$ tale che $\ker f = M / \varepsilon_f \cong Im_f$, ossia il quoziente \`e isomorfo all'immagine. Inoltre il quoziente ha una struttura di monoide:
\[
(M / \varepsilon_f , \cdot) \cong (Im_f, \ast)
\]
con $(Im_f, \ast)$ sottomonoide di $(A, \ast)$.
\end{prop}
\begin{proof}
Ogni morfismo di monoidi $f : (M, \cdot) \to (A, \ast)$ individua un sottomonoide di $(A, \ast)$, che \`e $(Im_f, \ast)$. 

Essendo $f$ un morfismo di monoidi, $\forall f(x), f(y) \in Im_f$, $f(x) \ast f(y) = f(x \cdot y) \in Im_f$, quindi $Im_f $ \`e chiuso rispetto a $\ast$. Devo poi verificare che $1_A \in Im_f \Leftarrow f(1_M) = 1_A$.

Anche $(\ker f, \cdot)$ \`e un monoide. Dobbiamo dimostrare l'esistenza dell'isomorfismo con $Im_f$.

$\ker f$ \`e l'insieme delle classi di equivalenza $[x] = \{ y \in M : x \ \varepsilon_f \ y \Leftrightarrow f(x) = f(y) \} \in \ker f$.

Definiamo l'operazione di prodotto fra classi come la classe del prodotto di due rappresentanti $[x] \cdot [z] = [x \cdot z]$ qualsiasi rappresentante scelgo della classe. Bisogna verificare che questa definizione sia indipendente dai rappresentnati! Lo faremo nella sezione \ref{congruenze}, in particolare nella dimostrazione \ref{congruenza_monoidi}. 

L'operazione fra classi \`e associativa, perch\'e \`e associativa l'operazione fra rappresentanti. Inoltre ho l'unit\`a $[1_M]$ in $\ker f$.

L'isomorfismo fra $(Im_f, \ast)$ e $(\ker f, \cdot)$ segue naturalmente dal fatto che $\ker f $ e $Im_f$ sono in biezione. Inoltre, essendo entrambi dei monoidi, la funzione $f$ \`e un isomorfismo di monoidi.
\end{proof}

\subsection{Potenze (iterazioni sui monoidi)}

\begin{defn}[Potenze]
A partire dal monoide $(M, \cdot)$ possiamo definire le iterazioni dell'operazione $\cdot$, ossia le potenze.

Sia $ a \in M$, si definisce:
\begin{enumerate}
    \item $a^0 = 1_M$
    \item $a^{n+1} = a \cdot a^{n}$
\end{enumerate}
\end{defn}
\begin{prop}[Commutativit\`a della potenza]
$\forall \ n \in \mathbb{N}$, $a \cdot a^n = a^n \cdot a$, ossia la potenza \`e commutativa.
\end{prop}
\begin{proof}
Si dimostra per induzione. Si vede subito che con $n = 0$, per definizione $a \cdot a^0 = a = a^0 \cdot a$.

Per definizione di potenza $a \cdot a^{n+1} = a \cdot a \cdot a^{n} $, per ipotesi induttiva $ a \cdot a^n \cdot a $ che di nuovo per definizione di potenza \`e $ a^{n+1} \cdot a$.
\end{proof}
\begin{prop}
Valgono tutte le propriet\`a tipiche delle potenze:
\[
a^{m + n} = a^m \cdot a^n
\]
\end{prop}
\begin{proof}
Si dimostra anche questo per induzione su $n$. Con $n = 0$, $a^{m+0} = a^m = a^m \cdot 1_M = a^m \cdot a^0$.

Passo induttivo. $a^{m + n + 1} = a \cdot a^{m + n}$ per definizione di potenze. Applicando l'ipotesi induttiva, $a \cdot a^{m + n} = a \cdot a^m \cdot a^n$. Per commutativit\`a $a \cdot a^m \cdot a^n = a^m \cdot a \cdot a^n = a^m \cdot a^{n+1}$.
\end{proof}

\begin{theorem}
Dato un monoide $(M, \cdot)$ ed un elemento $a \in M$, esiste un solo morfismo di monoidi $f : (\mathbb{N}, +) \to (M, \cdot)$ tale che $f(1) = a$, ed \`e $f(n) = a^n$.
\end{theorem}
\begin{proof}
$f$ \`e un morfismo di monoidi, quindi deve verificare che $f(m+n) = f(m) \cdot f(n)$ e che $f(0) = 1_M$. 

Per le propriet\`a delle potenze dimostrate precedentemente, $f(m+ n) = a^{m+n} = a^m \cdot a^n = f(m) \cdot f(n)$, e $f(0) = a^0 = 1_M$ per la definizione delle potenze. 

Inoltre verifica la condizione $f(1) = a$, infatti $f(1) = a^1 = a \cdot a^0 = a \cdot 1_M = a$.

Dobbiamo dimostrare l'unicit\`a di $f$. Sia $g : (\mathbb{N}, +) \to (M, \cdot )$ un morfismo tale che $g(1) = a$, dimostriamo che $\forall n \in \mathbb{N} $ $ g(n) = f(n) = a^n$.

Dimostriamolo per induzione su $n$. Per definizione di morfismo di monoidi, $g(0) = 1_M = f(0) = a^0$.

Supponiamo che $g(n) = f(n)$, per definizione di morfismo di monoidi $g(n+1) = g(1) \cdot g(n) = a \cdot g(n) = a \cdot f(n) = a \cdot a^n = a^{n+1}$.
\end{proof}

\begin{exmp}
Sia $\Gamma$ un insieme, la struttura algebrica $(\mathbb{P}(\Gamma), \cup)$ \`e in particolare un monoide. L'unione \`e associativa ($(A \cup B) \cup C = A \cup (B \cup C)$), ed esiste l'elemento neutro $\emptyset$.

Anche $(\mathbb{P}(\Gamma), \cap)$ \`e un monoide, con $\Gamma$ come elemento neutro, poich\'e $\forall \ A$, $\Gamma \cap A = A$. Abbiamo quindi due esempi di monoidi commutativi.

Fissato un insieme $S \subseteq \Gamma$ diverso da $\emptyset$, possiamo considerare il suo insieme delle parti $\mathbb{P}(S)$ e definire l'applicazione $f : \mathbb{P}(\Gamma) \to \mathbb{P}(S)$ tale che $f(A) = A \cap S$. 

Verifichiamo che questa applicazione \`e un morfismo di monoidi rispetto a $(\mathbb{P}(\Gamma), \cup)$ e $(\mathbb{P}(S), \cup)$. Dobbiamo dimostrare che $f( A \cup B) = f(A) \cup f(B)$. Infatti $f(A \cup B) = (A \cup B) \cap S = (A \cap S) \cup (B \cap S)$ per la propriet\`a distributiva, che \`e proprio $f(A) \cup f(B)$.

Inoltre l'applicazione conserva l'elemento neutro, poich\'e $f(\emptyset) = \emptyset \cap S = \emptyset$.

Verifichiamo che \`e un morfismo di monoidi anche rispetto $(\mathbb{P}(\Gamma), \cap)$ e $(\mathbb{P}(S), \cap)$. $f(A \cap B) = f(A) \cap f(B)$, infatti $(A \cap B) \cap S = (A \cap S) \cap (B \cap S)$ sempre per la propriet\`a distributiva. E anche in questo caso l'applicazione conserva l'elemento neutro, poich\'e $f(\Gamma) = \Gamma \cap S = S$, ed $S$ \`e proprio l'elemento neutro di $(\mathbb{P}(S), \cap)$.
\end{exmp}

\begin{exmp}
Sia $f : \mathbb{P}(\Gamma) \to \mathbb{P}(\Gamma)$ un'applicazione tale che $f(A) = \overline{A} = \{ x \in \Gamma : x \notin A\}$, ossia che associa ad $A$ il suo complementare $\overline{A}$. L'applicazione $f : (\mathbb{P}(\Gamma), \cup) \to (\mathbb{P}(\Gamma), \cap)$ \`e un morfismo di monoidi visto che verifica $f(A \cup B) = f(A) \cap f(B)$ per le leggi di De Morgan ($\overline{A \cup B} = \overline{A} \cap \overline{B}$) e $f(\emptyset) = \overline{\emptyset} = \Gamma$.

Possiamo considerare la stessa applicazione come un morfismo di monoidi da $f : (\mathbb{P}(\Gamma), \cap) \to (\mathbb{P}(\Gamma), \cup)$. Infatti $f(A \cap B) = \overline{A \cap B} = \overline{A} \cup \overline{B} = f(A) \cup f(B)$ e $f(\Gamma) = \overline{\Gamma} = \emptyset$.
\end{exmp}

\subsection{Congruenze\label{congruenze}}

\begin{defn}
Le congruenze sono relazioni d'equivalenza definite sulle strutture algebriche. Sia $\varepsilon$ una relazione d'equivalenza su $A$, con $(A, \cdot)$ monoide, si dice che $\varepsilon$ \`e una congruenza rispetto all'operazione $\cdot$ se, dati $a \ \varepsilon \ b$ e $c \ \varepsilon \ d$, ho che $a \cdot c \ \varepsilon \ b \cdot d$.
\end{defn}

Vuol dire che, dati $a \in [a]$ e $c \in [c]$, se $a \cdot c \in [a \cdot c]$ e ho una congruenza, allora $b \in [a]$ e $d \in [c]$ sono tali che $b \cdot d \in [a \cdot c]$. La congruenza fa s\`i che io possa definire operazioni sulle classi.

\begin{prop}
Riprendendo il teorema \ref{omomorfismo_monoidi}, abbiamo che considerato un morfismo di monoidi $f : (M, \cdot) \to (A, \ast)$, se definisco la relazione di equivalenza $\varepsilon_f$ tale che $x, y \in M$ sono $x \ \varepsilon_f \ y \Leftrightarrow f(x) = f(y)$, questa relazione di equivalenza \`e una congruenza.
\end{prop}
\begin{proof}\label{congruenza_monoidi}
$x \ \varepsilon_f \ y$, $z \ \varepsilon_f \ w \Rightarrow (x \cdot z) \ \varepsilon_f \ (y \cdot w)$.

Infatti $f(x \cdot z) = f(x) \ast f(z)$ e $f(y \cdot w) = f(y) \ast f(w)$. 
\end{proof}

Avevamo definito $\rho$ su $\mathbb{N} \times \mathbb{N}$, come $(a, b) \ \rho \ (c, d) \Leftrightarrow a+d = b+c$. Quindi a partire da $(M, \cdot) $ possiamo creare altri monoidi $(M^n, \cdot)$, ad esempio su $M^2 = M \times M$ in cui $(x, y) \cdot (z, t) = (x \cdot z, y \cdot t)$.

Ad esempio $(\mathbb{N}, +) \to (\mathbb{N} \times \mathbb{N}, +)$ in cui $(m, n) + (a, b) = (m+a, n+b)$ con l'elemento neutro $(0,0)$.

$\rho$ \`e una congruenza rispetto a + in $\mathbb{N} \times \mathbb{N}$. Inoltre, avendo visto che $\mathbb{N} \times \mathbb{N} / \rho = \mathbb{Z}$, abbiamo che $(\mathbb{Z}, +)$ \`e un monoide.

% WEB

\section{Gruppi}

\begin{defn}
$(G, \cdot)$ \`e un gruppo se:
\begin{description}
    \item[1G] $(G, \cdot)$ \`e un monoide
    \item[2G] $\forall \ a \in G $, $ \exists \ b \in G $ tale che $a \cdot b = 1_G$, con $b$ comunemente indicato come $a^{-1}$ e detto inverso di $a$.
\end{description}
\end{defn}

Possiamo definire un morfismo di gruppi. Un morfismo conserva strutture e propriet\`a, deve quindi essere un morfismo di monoidi che manda l'inverso nell'inverso.
\begin{defn}[Morfismo di gruppi]
Quindi $f : (G, \cdot) \to (G', \ast)$ \`e un morfismo di gruppi se:
\begin{enumerate}
    \item \`e un morfismo di monoidi
    \item $\forall a \in G f(a^{-1}) = (f(a))^{-1}$
\end{enumerate}
\end{defn}
\begin{prop}
Queste due propriet\`a sono la conseguenza di una sola, ossia che il morfismo conserva le operazioni. Infatti se $f(a \cdot b) = f(a) \ast f(b)$ allora sono vere tutte le propriet\`a.
\end{prop}
\begin{proof}
Un morfismo che conserva le operazioni manda le unit\`a nelle unit\`a: $f(1_G) = f(1_G \cdot 1_G) = f(1_G) \ast f(1_G)$. Essendo entrambi gruppi hanno l'inverso, quindi moltiplicando entrambi i lati per l'inverso di $f(1_G)$ abbiamo $(f(1_G))^{-1} \ast f(1_G) = (f(1_G))^{-1} \ast f(1_G) \ast f(1_G) \Rightarrow 1_{G'} = f(1_G)$.

Inoltre, se il morfismo conserva le operazioni manda gli inversi negli inversi, ossia $f(a^{-1}) = (f(a))^{-1}$. Infatti $f(a) \ast f(a^{-1}) = f(a \cdot a^{-1}) = f(1_G) = 1_{G'} = f(a) \ast (f(a))^{-1}$.
\end{proof}

\subsection{Sottogruppi}

\begin{defn}[Sottogruppo]
Partendo da $(G, \cdot)$ e scegliendo $S \subseteq G$ diverso da $\emptyset$, un sottogruppo $(S, \cdot)$ deve essere:
\begin{itemize}
    \item Chiuso: $\forall \ s, s' \in S$, $s \cdot s' \in S$
    \item Deve contenere l'unit\`a: $1_G \in S$ (quindi $S$ \`e un sottomonoide di $G$)
    \item Per essere anche un sottogruppo, $S$ deve essere chiuso rispetto agli inversi: $s \in S \Rightarrow s^{-1} \in S$.
\end{itemize}
\end{defn}
\begin{prop}
Condizione necessaria e sufficiente affinch\'e $(S, \cdot)$ con $S \neq \emptyset$ sia un sottogruppo del gruppo $(G, \cdot)$ \`e:
\[
a, b \in S \Rightarrow a^{-1} \cdot  b \in S
\]
\end{prop}
\begin{proof}
Dimostrare che \`e condizione necessaria \`e banale. Per definizione di sottogruppo $a^{-1}$ \`e in $S$, ed essendo chiuso $a^{-1} \cdot b \in S$.

Dobbiamo dimostrare che \`e sufficiente. $S \neq \emptyset$, quindi ha almeno un elemento $a \in S$. Prendiamo $b = a $, per la propriet\`a indicata sopra $a \cdot a^{-1} \in S \Rightarrow 1_G \in S$. Quindi $S$ contiene almeno l'elemento neutro.

Contiene l'inverso: $\forall \ x \in S $, $ x^{-1} \in S$ sempre per la propriet\`a sopra. Infatti prendendo $a = x$ e $b = 1_G$, $a^{-1} \cdot b \in S$ ossia $x^{-1} \cdot 1_G \in S \Rightarrow x^{-1} \in S$.

\`E chiuso: $\forall \ s, s' \in S \Rightarrow s \cdot s' \in S$. Abbiamo appena visto che $s \in S \Rightarrow s^{-1} \in S$, quindi per la solita propriet\`a ho che $(s^{-1})^{-1} \cdot s' \in S \Rightarrow s \cdot s' \in S$.
\end{proof}

% SONO ARRIVATO QUI

% $(\mathbb{Z}, +) \to (\mathbb{N} \times \mathbb{N}, +) / \rho$.

I sottogruppi di $(\mathbb{Z}, +)$ sono tutti e solo i gruppi $(k \mathbb{Z}, +)$. $(\mathbb{Z}, \cdot)$ non \`e un gruppo perch\'e non ha l'inverso per ogni elemento.

Dati $a, b \in G$, voglio conoscere l'inverso del prodotto $a \cdot b$, ossia $(a \cdot b)^{-1}$. Solitamente un gruppo $(G, \cdot)$ non \`e commutativo. Solo se il gruppo \`e commutativo ho che $(a \cdot b)^{-1} = a^{-1} \cdot b^{-1}$.

Consideriamo il gruppo simmetrico $(S_n, \circ)$, definito sull'insieme delle funzioni iniettive da un insieme con $n$ elementi in s\'e stesso con l'operazione di composizione. Non \`e un gruppo commutativo.

Prendiamo le due funzioni $\sigma$ e $\tau$ dal punto di vista dell'occupazione in figura \ref{fig:gruppo_simmetrico}. Se voglio trovare l'inverso $pi$ di $\sigma \circ \tau$ tale che $(\sigma \circ \tau) \circ \pi = i$ devo usare $\pi = (\tau^{-1} \circ \sigma^{-1})$.

\begin{figure}[ht]
\centering
\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma$} \\
\hline
1 & 2 & 3 & 4 \\
2 & 3 & 1 & 4
\end{tabular} \qquad
\begin{tabular}{cccc}
\multicolumn{4}{c}{$\tau$} \\
\hline
1 & 2 & 3 & 4 \\
1 & 2 & 4 & 3
\end{tabular}

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma \circ \tau$} \\
\hline
1 & 2 & 3 & 4 \\
1 & 2 & 4 & 3 \\
2 & 3 & 4 & 1
\end{tabular} \qquad
\begin{tabular}{cccc}
\multicolumn{4}{c}{$\tau \circ \sigma$} \\
\hline
1 & 2 & 3 & 4 \\
2 & 3 & 1 & 4 \\
2 & 4 & 1 & 3
\end{tabular}
\caption{\label{fig:gruppo_simmetrico}Il gruppo simmetrico non \`e commutativo}
\end{figure}

Quindi, l'inverso del prodotto \`e il prodotto degli inversi scambiati di posto:
\[
(a \cdot b) \cdot (b^{-1} \cdot a^{-1}) = a \cdot (b \cdot b^{-1}) 
\cdot a^{-1} = a \cdot 1_G \cdot a^{-1} = 1_G
\]

Un'applicazione $f : G \to G'$ \`e un morfismo di gruppi se $\forall a, b \in G$ ho che $f(a \cdot b) = f(a) \ast f(b) \Rightarrow f(1_G) = 1_{G'}$ e $f(a^{-1}) = (f(a))^{-1}$.

\begin{exmp} 
La funzione $\log : (\mathbb{R}^{+}, \cdot) \to (\mathbb{R}, +)$ \`e un morfismo di gruppi, perch\'e $\log(a \cdot b) = \log(a) + \log(b)$.

Anche la funzione $\exp : (\mathbb{R}, +) \to (\mathbb{R}^{+}, \cdot)$ \`e un morfismo di gruppi, infatti  $\exp(a + b) = \exp(a) \cdot \exp(b)$.

Anche l'iterazione della somma \`e un morfismo di gruppi. $f_n : (\mathbb{Z}, +) \to (\mathbb{Z}, +) $, infatti $\forall \ z \in \mathbb{Z}$, $f_n(z) = n \cdot z$
\end{exmp}

\subsection{Nucleo di un morfismo di gruppi}

Ogni morfismo di gruppi $f$ individua due sottogruppi:
\begin{itemize}
    \item $Im_f \subseteq G'$
    \item $\ker f \subseteq G$. Diversamente dalle definizioni gi\`a viste, in questo caso il nucleo $\ker f = \{ u \in G : f(u) = 1_{G'}\}$ \`e una classe, ossia $\ker f \in G / \varepsilon_f$
\end{itemize}

Con i monoidi avevamo una struttura associativa $(M, \cdot)$ contenente l'unit\`a $1_M$. Il $\ker f$ l'abbiamo chiamato ``quoziente'', ossia:
\[
\ker f = M / \varepsilon_f
\]

\begin{figure}[ht]
\centering
\begin{tikzpicture}
  \node (A) {$A$};
  \node (f) [right of=A, node distance=2cm] {$f$};
  \node (B) [right of=f, node distance=2cm] {$B$};
  \node (a) [below of=A, node distance=1cm] {$a$};
  \node (b) [below of=a, node distance=1cm] {$b$};
  \node (c) [below of=b, node distance=1cm] {$c$};
  \node (d) [below of=c, node distance=1cm] {$d$};
  \node (e) [below of=d, node distance=1cm] {$e$};
  \node (1) [below of=B, node distance=1cm] {$1$};
  \node (2) [below of=1, node distance=1cm] {$2$};
  \node (3) [below of=2, node distance=1cm] {$3$};
  \node (4) [below of=3, node distance=1cm] {$4$};
  \node (5) [below of=4, node distance=1cm] {$5$};
  \node (6) [below of=5, node distance=1cm] {$6$};
  \node (7) [below of=6, node distance=1cm] {$7$};
  \path[->]  (a) edge node {} (3)
            (b) edge node {} (3)
            (c) edge node {} (4)
            (d) edge node {} (4)
            (e) edge node {} (7)
            ;
\end{tikzpicture}
\caption{\label{fig:esempio_funzione}$\ker f = \{ \{a, b \}, \{ c, d \}, \{ e \}\}$ }
\end{figure}

Nel caso in figura \ref{fig:esempio_funzione} $\ker f = \{ \{a, b \}, \{ c, d \}, \{ e \}\}$. Ho \textit{bisogno} di sapere quali classi ci sono per ricostruire la funzione. Per conoscere la $f$ devo sapere tutti i blocchi della partizione, non posso ricostruire gli altri blocchi da un blocco solo.

Con i gruppi non \`e cos\`i. Mi basta la classe degli elementi che vanno nell'unit\`a. Se conosco questa classe le conosco tutte. Infatti fissato il $\ker f$ conosco tutti gli elementi che hanno la stessa immagine di $a$, ossia $a \cdot \ker f = [a]$.

Abbiamo un morfismo di gruppi $ f : (G, \cdot ) \to (G', \ast)$. Dimostriamo intanto che il nucleo \`e un sottospazio, ossia un sottogruppo.

$\ker f = [1_G]$ conosco tutti gli elementi che finiscono nell'unit\`a di $G'$

CNES afficnhe un sottoinsieme sia un sottogruppo \`e che se $a, b \in S \Rightarrow a^{-1} b \in S$.

Prendiamo $u, v \in \ker f$. La tesi \`e che $u^{-1} \cdot v \in \ker f$. Quindi $f ( u^{-1} \cdot v ) = 1_{G'}$.
\[
f( u^{-1} \cdot v ) = f(u^{-1}) \ast f(v) = f(u)^{-1} \ast f(v)
\]
Ma $f(u)^{-1} = 1_{G'}$, quindi ho:
\[
f(u)^{-1} \ast f(v) = 1_{G'} \ast 1_{G'} = 1_{G'}
\]

\subsection{Teorema di omomorfismo per i gruppi}

Sia $f : (G, \cdot) \to (G', \ast)$ un morfismo di gruppi, allora $\varepsilon_f$ \`e una congruenza e il gruppo $G / \varepsilon_f$ \`e isomorfo al gruppo $(Im_f, \ast)$. Ogni elemento $[a] \in G / \varepsilon_f$ \`e del tipo $a \cdot \ker f$.
\[
F : (G / \varepsilon_f, \cdot) \to (Im_f, \ast)
\]
\[
\forall [a] \in G / \varepsilon_f [a] = a \cdot \ker f
\]
Dimostrazione:
$b \in [a] \Rightarrow f(a) = f(b)$ per definizione hanno la stessa immagine tramite il morfismo.

Quindi moltiplico entrambi i membri per $f(a)^{-1}: f(a)^{-1} \ast f(b) = 1_{G'} \Rightarrow 1_{G'} = f(a)^{-1} \ast f(b) = f(a^{-1} \cdot b)$

Quindi $u = (a^{-1} \cdot b ) \in \ker f e b = a \cdot u = a \cdot (a^{-1} \cdot b)$

Viceversa, dobbiamo prendere $b \in a \cdot \ker f \Rightarrow b = a \cdot u$. Ha per forza la stessa immagine di $a$, infatti $f(b) = f(a \cdot u) = f(a) \cdot f(u) = f(a) \cdot 1_G = f(a)$. Segue che $b$ \`e nella classe di $a, b \in [a]$.

Non essendo commutativo ho che $b = a \cdot u = v \cdot a$. Posso vedere $b \in a \cdot \ker f$ sia in $\ker f \cdot a$.

La prima \`e la classe laterale sinistra, la seconda \`e la classe laterale destra.
\[
\forall a \in G a \cdot ker f = \ker f \cdot a
\]
\[
b = u \cdot a
\]
\[
f(b) = f(u) \cdot f(a) = 1_{G'} \cdot f(a)
\]
Proiezioni. La seguente \`e la prima proiezione
\[
p_1 : \mathbb{R} \times \mathbb{R} \to \mathbb{R}
\]
\[
p_1 (x, y) = x
\]
\[
p_1 : (\mathbb{R} \times \mathbb{R}, +) \to (\mathbb{R}, +)
\]
Qual \`e l'immagine $Im_{p_1}$? $Im_{p_1} = \{ r \in \mathbb{R} : \exists (x, y) p_1 (x, y) = r \}$. In questo caso l'immagine \`e tutto $\mathbb{R}$. Infatti $\forall r \in \mathbb{R} p_1(r, 0) = r$.

Adesso troviamo il nucleo.
\[
\ker f = \{ (x, y) \in \mathbb{R} \times \mathbb{R} : p_1(x, y) = 0 \} = \{ (0, y) : y \in \mathbb{R} \}
\]
L'unit\`a di $G 1_G = (0, 0) \in \ker p_1$

0 \`e l'elemento neutro di $(\mathbb{R}, +)$.
\[
(2, 3) \in \mathbb{R} \times \mathbb{R}, p_1(2, 3) = 2
\]
\[
[(2, 3)] = \{ (x, y) \in \mathbb{R} \times \mathbb{R} : f(x, y) = 2\}
\]
Applicando il teorema di omomorfismo visto prima vediamo subito che \`e:
\[
[(2,3)] = (2, 3) + \ker p_1 = \{ (2, 3) + (0, y) = (2, y + 3) \}
\]
Altro esempio:
$\mathbb{R}[x] =$ insieme dei polinomi in una indeterminata $x$

un polinomio \`e una espressione formale del tipo $a_0 + a_1 x + \dots a_n x^n$ dove $a_n \neq 0$ e $n$ si dice grado del polinomio.

C'\`e una differenza fra $x \to$ indeterminata e $x \to $ variabile. L'indeterminata fa parte dei polinomi, e vuol dire che $x$ \`e un simbolo. Variabile vuol dire che \`e un elemento di un insieme, ossia $x \in E$. In genere si confonde indeterminata con variabile, perch\'e quando si parla di polinomi la $x$ \`e indeterminata, ma ogni polinomio individua una funzione polinomiale. $p : R \to R a \mapsto p(a)$
\[
p(x) = 1 + 2x
\]
individua la funzione polinomiale $p : R \to R \forall a \in R$ associa $1 + 2 \cdot a = p(a)$. Nel caso dei numeri reali, questa funzione \`e una biezione. Se due polinomi hanno la stessa funzione polinomiale, allora sono lo stesso polinomio. Non \`e vero se prendo altri insiemi.

Per fare i polinomi bisogna avere un campo.

Se prendo $Z_2 = {0,1}$, ossia i resti della divisione per 2. Possiamo definire due operazioni, di somma e di prodotto.

\begin{tabular}{c|cc}
+ & 0 & 1 \\
\hline
0 & 0 & 1 \\
1 & 1 & 0
\end{tabular}

$Z / \equiv_2$, congruenza modulo 2.

\begin{tabular}{c|cc}
$\cdot$ & 0 & 1 \\
\hline
0 & 0 & 0 \\
1 & 0 & 1
\end{tabular}

Un campo \`e un gruppo rispetto a $+$ e un gruppo rispetto a $\cdot$ senza elemento neutro (0).

Posso creare i polinomi a coefficienti in $Z_2$, ossia $Z_2[x]$, ad esempio $1 + x$. La funzione polinomiale rispetto a questo polinomio \`e:
\begin{itemize}
    \item per $x = 0 \to p(0) = 1$
    \item per $x = 1 \to p(1) = 0$
\end{itemize}
Ma dato il polinomio $1 + x^2$ ho:
\begin{itemize}
    \item per $x = 0 \to p(0) = 1$
    \item per $x = 1 \to p(1) = 0$
\end{itemize}
Sono quindi due polinomi diversi che hanno la stessa funzione polinomiale.

Due polinomi sono uguali se hanno tutti i coefficienti uguali.

$(R[x], +)$ \`e un gruppo commutativo. Come funziona il +? Sommo i coefficienti. L'elemento neutro \`e il polinomio nullo, ossia il polinomio con tutti i coefficienti uguali a 0. Si indica con $\underline{0}$. Il polinomio nullo ha grado -1.

Posso definire un morfismo di gruppi su tutta sta merda.

Prendo tutti i polinomi di grado minore o uguale a due, e li indico $R_2[x]$.

Prendo l'applicazione $f : (R_2[x], +) \to (R^2, +)$ definito come segue:
\[
f(a_0 + a_1 \cdot x + a_2 \cdot x^2) = (a_2, a_1 + a_2)
\]
Quindi $1 + 2x \mapsto (0, 2)$.

Qual \`e l'immagine di questa $f$? 
\[
Im_f = \{ (r, s) \in R^2 : \exists p(x) t.c. f(p(x)) = (r,s)\} = R^2
\]
\[
(r, s) = f(0 + (s - r) x + r x^2)
\]
Troviamo il nucleo.
\[
\ker f = \{ p(x) \in R^2[x] : f(p(x)) = (0, 0)\}
\]
Quindi sono tutti i polinomi di grado 0 pi\`u il polinomio nullo, dovendo avere $a_2 = 0$ e $a_1 = 0$.

Tutti i polinomi $[p(x)] = a_0 + a_1 x + a_2 x^2$ devono potersi scrivere come $p(x) + \ker f$.
\[
f(p(x)) = (a_2, a_1 + a_2)
\]
\[
p(x) + \ker f
\]
\[
q(x) \in [p(x)] sono q(x) = p(x) + a_0
\]
con $a_0 \in \ker f$

Esercizio:

$(G, \cdot)$, $(G', \ast)$, poi abbiamo il morfismo $f : (G, \cdot) \to (G', \ast)$
\[
\ker f \subseteq G
\]
\[
Im_f \subseteq G'
\]
Caratterizzano il morfismo, questi due gruppi. f \`e un morfismo iniettivo (monomorfismo) $\Leftrightarrow \ker f = \{ 1_G\}$. Il morfismo \`e suriettivo (epimorfismo) $\Leftrightarrow$ solo se $Im_f = G'$.

Il primo caso \`e evidente, il $\ker f$ ha solo un elemento quindi la classe degli elementi con la stessa immagine $[a] = a \cdot \ker f$ ha un solo elemento, ossia $a$. Si pu\`o anche dimostrare direttamente.

$f$ \`e iniettiva per ipotesi. La tesi \`e che il nucleo \`e costituito da un solo elemento $\ker f = \{ 1_G \} $ ossia $f(1_G) = 1_{G'}$

Viceversa se $\ker f = \{ 1_G \} \Rightarrow f(a) = f(b) \Rightarrow f(a) \cdot f(b)^{-1} = 1_{G'} = f(a \cdot b^{-1}) = 1_{G'} \Rightarrow a \cdot b^{-1} = 1_G \Rightarrow a = b$

Se prendiamo $S$ sottogruppo di $G$ possiamo considerare la classe laterale destra $a S$ e la classe laterale sinistra $S a$. Lo vediamo la prossima volta. 

\subsection{Teorema di omomorfismo per i gruppi}

Dato un morfismo $f : (G, \cdot) \to (G', \ast)$, allora 
\begin{enumerate}
    \item $\varepsilon_f$ individuata da $f$ ($x \ \varepsilon_f \ y \Leftrightarrow f(x) = f(y)$) \`e una congruenza
    \item Il gruppo $(G / \varepsilon_f, \cdot)$ \`e isomorfo al sottogruppo $(Im_f, \ast)$ di $(G', \ast)$. Questo vale per ogni struttura algebrica.
\end{enumerate}

$f$ individua due sottogruppi, $\ker f = \{ u \in G : f(u) = 1_{G'} \} \le G$, $Im_f = \{ x' \in G' : \exists x \in G f(x) = x'\} \le G'$. 
\[
\forall a \in G [a] = a \cdot \ker f = \ker f \cdot a
\]
\begin{prop}
Tutte le classi hanno la stessa cardinalit\`a $|[a]| = |a \cdot \ker f| = |\ker f|$
\end{prop}
\begin{proof}
Bisogna far vedere che esiste una corrispondenza biunivoca.
\[
\forall a \in G \varphi_a : \ker f \to a \cdot \ker f
\]
\[
\forall u \in \ker f \varphi_a (u) = a \cdot u \in a \cdot \ker f
\]
$\varphi_a$ \`e biunivoca. 

$\varphi_a$ \`e iniettiva, infatti $\forall u$, $v \in \ker f $ tali che $\varphi_a (u) = \varphi_a (v)$, ho che a $\cdot u = a \cdot v \Rightarrow$ essendo in un gruppo $a$ ha l'inverso, quindi $a^{-1} \cdot a \cdot u = a^{-1} \cdot a \cdot v \Rightarrow u = v$.
\end{proof}

Vediamo cosa succede se prendiamo un sottogruppo qualunque.

Sia $S \le G$ un sottogruppo qualunque di $G$. Prendo $a \in G$ e moltiplico tutti gli elementi di $S$ per $a$, ossia faccio $a \cdot S$ e $S \cdot a$.

$a \cdot S = \{ x \in G : x = a \cdot s con s \in S \}$ \`e la classe laterale sinistra di $S$

$S \cdot a = \{ x \in G : x = s \cdot a con s \in S \}$ \`e la classe laterale destra di $S$

Per lo stesso motivo di prima tutte le classi laterali hanno la stessa cardinalit\`a di $S |a \cdot S| = |S| = |S \cdot a| \forall a \in G$

Prendiamo l'insieme di sottoinsiemi sinistri
\[
\{ a \cdot S\}_{a \in G} a \cdot S \subseteq G
\]
$a \cdot S$ non \`e un sottogruppo perch\'e non contiene l'unit\`a, ma \`e un sottoinsieme. L'insieme delle classi sinistre \`e una partizione di $G$.
\begin{enumerate}
    \item $\bigcup_{a \in G} a \cdot S = G$
    \item $a \cdot S \neq \emptyset$, infatti necessariamente $a \in a \cdot S$, essendo $a = a \cdot 1_G$ e $1_G \in S$
    \item $a \cdot S \cap a \cdot S \neq \emptyset \Rightarrow a \cdot s = b \cdot S$
\end{enumerate}
Dimostriamo il punto tre.

$a \cdot S \cap b \cdot S \neq \emptyset \Rightarrow a \cdot S = b \cdot S$

\[
c \in a \cdot S \cap b \cdot S
\]
\[
c = a \cdot s = b \cdot v con s, v \in S
\]
\`e l'ipotesi

La tesi \`e:
$x \in a \cdot S \Rightarrow = a \cdot u$ con $u \in S$
Per ipotesi ho $a = c \cdot s^{-1} \Rightarrow x = c \cdot s^{-1} \cdot u$, ma sempre per ipotesi ho che $x = b \cdot v \cdot s^{-1} \cdot u$. Quindi $x \in b \cdot S$, avendo che $(v \cdot s^{-1} \cdot u) \in S$.

Se $\{a \cdot S\}_{a \in G}$ \`e una partizione di $G$, individua in $G$ una relazione di equivalenza che indichiamo con $\lateralsx{S}$ (perch\'e che $S$ \`e una classe laterale sinistra).

Dico che due elementi sono equivalenti se sono nello stesso blocco. Ossia dati $x, y \in G$ dico $x \lateralsx{S} y \Leftrightarrow \exists a \in G x, y \in a \cdot S \Leftrightarrow x = a \cdot s$ e $y = a \cdot v$ con $s, v \in S$. Si pu\`o semplificare ulteriormente questa definizione, perch\'e se un elemento $x$ \`e nella classe posso prendere $x$ come rappresentante, e quindi dire che $x \in y \cdot S$ o che $y \in x \cdot S$ o che $x \cdot S = y \cdot S$ (sono tutte definizioni equivalenti).

Quindi posso scrivere $x \in y \cdot S$ come $x = y \cdot s$ con $s \in S$.
\[
s = y^{-1} \cdot x \in S
\]
Qual \`e la differenza con il nucleo? Nel nucleo le classi laterali coincidono, in generale no. Le classi laterali hanno la stessa cardinalit\`a ma non sono identiche.

Le due relazioni di equivalenza destra e sinistra (simboli qui) non sono uguali, e non sono congruenze.
\[
a \cdot S \neq S \cdot a
\]
Nel caso del nucleo invece abbiamo che $a \cdot \ker f = \ker f \cdot a$, e la relazione di equivalenza destra e sinistra \`e una sola, ossia $\varepsilon_f$, ed \`e una congruenza.

Facciamo un esempio. Consideriamo $S_4$

$(G, \cdot)$ e $a \in G$, possiamo indicare con $< a > =$ sottogruppo generato da $a \in G$ costitiuto da tutte le potenze generate da $a$. Per le propriet\`a delle potenze \`e un sottogruppo, infatti contiene $1_G = a^{0}$.
\[
S_4
\]
\[
< a > = \{ a^{z} : z \in \mathbb{Z} \}
\]
Contiene anche l'inverso di $a^{n}$, ossia $a^{-n}$

Prendiamo il sottogruppo generato da questa permutazione, e tutte le potenze generate da questa $\sigma$:

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma$} \\
1 & 2 & 3 & 4 \\
2 & 3 & 1 & 4 
\end{tabular}

\[
\sigma^{0} = id
\]
\[
\sigma^{1} = \sigma
\]
$\sigma^{2}$ cosa \`e?

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma^{2}$} \\
1 & 2 & 3 & 4 \\
2 & 3 & 1 & 4 \\
3 & 1 & 2 & 4
\end{tabular}

Se poi faccio $\sigma^{3}$ riottengo l'identit\`a.

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma^{3}$} \\
1 & 2 & 3 & 4 \\
3 & 1 & 2 & 4 \\
1 & 2 & 3 & 4 
\end{tabular}

Quindi il gruppo $H = < \sigma > = \{ 1 , \sigma, \sigma^{2} \}$. L'inversa di $\sigma$ \`e $\sigma^{2}$. $H$ \`e un gruppo finito di ordine 3.

Facciamo la relazione di equivalenza e la classe laterale.

Prendiamo due elementi equivalenti, $\mu$  e $\tau \Leftrightarrow \sigma \tau^{-1} \in H$. Quindi $\mu \tau^{-1} = \rho \in H$, quindi o l'identit\`a, o $\sigma$ o $\sigma^{2}$.

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\tau$} \\
1 & 2 & 3 & 4 \\
2 & 1 & 4 & 3
\end{tabular}

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma \cdot \tau$} \\
1 & 2 & 3 & 4 \\
2 & 1 & 4 & 3 \\
3 & 2 & 4 & 1
\end{tabular}

Quindi $\mu$ \`e:

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\mu$} \\
1 & 2 & 3 & 4 \\
3 & 2 & 4 & 1
\end{tabular}

Prendiamo $\tau'$

\begin{tabular}{cccc}
1 & 2 & 3 & 4 \\
4 & 3 & 2 & 1
\end{tabular}

Applichiamo $\sigma$

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\sigma \cdot \tau'$} \\
1 & 2 & 3 & 4 \\
4 & 3 & 2 & 1 \\
4 & 1 & 3 & 2
\end{tabular}

Otteniamo $\mu'$ equivalente a $\tau'$

\begin{tabular}{cccc}
\multicolumn{4}{c}{$\mu'$} \\
1 & 2 & 3 & 4 \\
4 & 1 & 3 & 2
\end{tabular}

% Dobbiamo far vedere ora che \mu, \tau, \mu' e \tau' sono nella stessa classe.

Siamo nella classe destra, avendo fatto $\sigma \tau$ (va vista come composizione).

La congruenza mi d\`a modo di definire il prodotto fra classi. 

Dati $a, b$ nella classe 1, dati $a', b'$ nella classe 2. Le classi sono definite sulla struttura $(A, \cdot)$. Vogliamo definire il prodotto fra classi, ossia $[1] \cdot [2] = [3]$. 

La congruenza fa in modo che comunque prendo i rappresentanti i prodotti vanno sempre nella stessa classe. Quindi $a \cdot a'$ e $b \cdot b' \in [3]$.

Possiamo vedere che $\tau$ per $\tau'$ e $\mu$ per $\mu'$ non vanno nella stessa classe.

Che ordine ha il sottogruppo $H$? Lo possiamo dire per il teorema di Lagrange.

Teorema di Lagrange
$(G, \cdot)$ gruppo finito, la cardinalit\`a di $G$ si dice ordine.

Prendiamo $|G| = n$, allora se $H$ \`e un sottogruppo di $G$, l'ordine di $G$ \`e diviso dall'ordine di $H$
\[
\frac{|G|}{|H|}
\]
Questo intero \`e detto indice di $H$.

Un gruppo di ordine un numero primo ha due sottogruppi.

$G \to \{ a H\}_{a \in G}$
\`e una partizione di $G$
\[
|a H| = |H|
\]
\[
|G / \lateralsx{H}| = \frac{|G|}{|H|}
\]
\begin{defn}
un sottogruppo $N$ di $G$ si dice normale se $\forall a \in G$ $a N = N a$, ossia ogni classe laterale destra \`e uguale alla classe laterale sinistra. I nuclei dei morfismi sono sottogruppi normali.
\end{defn}
CNES affinch\'e $N$ sia normale \`e che $\forall a \in G$ e $\forall u \in N$, $a \cdot u \cdot a^{-1} \in G$. Deriva banalmente da $a \cdot N = N \cdot a$

CNES affinch\'e $N$ sia normale \`e che $\lateraldx{N}$ (o $\lateralsx{N}$) \`e una congruenza.

Tutti i nuclei dei morfismi sono sottogruppi normali.

Ogni permutazione \`e una biezione che pu\`o essere indicata sia dal punto di vista dell'occupazione sia dal punto di vista della distribuzione (come parola).

\[
\sigma \in S_8
\]

\begin{tabular}{*{8}{c}}
\multicolumn{8}{c}{$\sigma$} \\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
1 & 7 & 4 & 6 & 5 & 2 & 3 & 8
\end{tabular}

O come parola:
\[
17465238
\]
Possiamo indicare le permutazioni come composte di cicli.
\[
\sigma = (1) (2 7 3 4 6) (5) (8)
\]
$(2 7 3 4 6)$ significa che il 2 va nel 7, il 7 nel 3, il 3 nel 4 e il 4 nel 6.

$\mu (3 1) (5 4 2) (8 7 6)$ \`e un prodotto di cicli. Corrisponde alla permutazione:

\begin{tabular}{*{8}{c}}
\multicolumn{8}{c}{$\mu$} \\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
3 & 5 & 1 & 2 & 4 & 8 & 6 & 7
\end{tabular}

Le permutazioni vengono rappresentate come prodotti di cicli. I cicli di lunghezza 1 non vengono scritti, visto che ogni elemento va a finire in s\'e stesso. Quindi $\sigma = (1) (2 7 3 4 6) (5) (8)$ posso scriverla come $\sigma = (2 7 3 4 6)$.

Data una permutazione
\[
\sigma \in S_n 
\]
Definita su
\[
[n] = \{1 \dots n\}
\]
Ho la relazione di equivalenza sui cicli
$x equiv_sigma y \Leftrightarrow \exists n \in \mathbb{N} $ t.c. $ y = \sigma^{n} (x)$

\textbf{Esercizio:} questa \`e una relazione di equivalenza che divide $[n]$ in classi di equivalenza. Le classi sono i cicli.

Ad esempio, nel caso del $\sigma$ di prima, $7 = \sigma(2)$, $3 = \sigma^{2}(2)$, $4 = \sigma^{3} (2)$, $6 = \sigma^{4} (2)$.

$x$ \`e equivalente a tutti gli elementi $\sigma (x), \sigma^{2} (x), \dots \sigma^{t}(x)$ fino alla $t$-esima permutazione che torna in $x$ (altrimenti il ciclo sarebbe infinito).
\[
\mu_x : [n] \to [n]
\]
Definita come:
\[
\mu_x (y) =
\begin{cases}
y se y \notin [x] \\
\sigma(y) se y \in [x]
\end{cases}
\]
Quindi $\mu_x$ si comporta come $\mu$ nella partizione individuata da $x$, e tutti gli altri restano fissi.

Quindi $\mu_3$ \`e:

\begin{tabular}{*{8}{c}}
\multicolumn{8}{c}{$\mu_3$} \\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
3 & 2 & 1 & 4 & 5 & 6 & 7 & 8
\end{tabular}
\[
\mu_3 = \mu_1
\]
$\mu_5 = \mu_4 = \mu_2$ si comporta come $\mu$ solo sulla partizione individuata da 5:

\begin{tabular}{*{8}{c}}
\multicolumn{8}{c}{$\mu_5$} \\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
1 & 5 & 3 & 2 & 4 & 6 & 7 & 8
\end{tabular}

$\mu_6 = \mu_7 = \mu_8$ si comporta come $\mu$ solo sulla partizione individuata da 6:

\begin{tabular}{*{8}{c}}
\multicolumn{8}{c}{$\mu_6$} \\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\
1 & 2 & 3 & 4 & 5 & 8 & 6 & 7
\end{tabular}

$\mu$ come prodotto di cicli si scrive come prodotto di cicli, ossia posso comporre $\mu_3$, $\mu_5$ e $\mu_6$ per ottenere $\mu$.

\begin{tabular}{*{9}{c}}
\multicolumn{9}{c}{$\mu = \mu_3 \circ \mu_5 \circ \mu_6$} \\
1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & \\
3 & 2 & 1 & 4 & 5 & 6 & 7 & 8 & $\mu_3$ \\
3 & 5 & 1 & 2 & 4 & 6 & 7 & 8 & $\mu_5$ \\
3 & 5 & 1 & 2 & 4 & 8 & 6 & 7 & $\mu_6$
\end{tabular}

Questo si chiama rappresentazione delle permutazioni come cicli disgiunti.

Non si possono omettere le parentesi, o si avrebbe una parola.

Con $\mathbb{N}$ possiamo trovare una rappresentazione standard (o canonica) dei cicli, senza parentesi.

Consideriamo i cicli (3 1 2) 5 (7 8) (4 6)

\begin{enumerate}
    \item descrivo i cicli partendo dall'elemento maggiore:
    (3 1 2) 5 (8 7) (6 4)
    \item ordino in maniera crescente in base al primo elemento
    (3 1 2) 5 (6 4) (8 7)
    \item ora posso togliere le parentesi, perch\'e so che i cicli finiscono al primo elemento non decrescente
    3 1 2 5 6 4 8 7
\end{enumerate}

Rappresentazione canonica o standard di una permutazione di $[n]$.

Trasposizioni = permutazioni che scambiano due elementi. Quindi hanno un solo ciclo di lunghezza 2 e tutti gli altri di lunghezza 1.

\begin{theorem}
Ogni permutazione si pu\`o scrivere come un prodotto di trasposizioni. Il numero di trasposizioni varia.
\end{theorem}

Se $\sigma$ si esprime come un prodotto di un numero pari di trasposizioni, allora ogni altro prodotto di trasposizioni che mi d\`a $\sigma$ ha un numero pari di trasposizioni. Vale anche con i dispari.

\begin{defn}
Una permutazione \`e pari se si esprime come prodotto di un numero pari di trasposizioni, dispari se si esprime come prodotto di un numero dispari di trasposizioni.
\end{defn}

$A_n =$ insieme delle permutazioni pari $\subseteq S_n$

\`E un sottogruppo di $S_n$?

$1 \in A_n$ (contiene l'unit\`a)

Deve essere un gruppo rispetto alle permutazioni. $\sigma, \mu \in A_n \Rightarrow (\sigma \cdot \mu) \in A_n$.

Allo stesso modo $\sigma^{-1} \in A_n$. Come si ottiene $\sigma^{-1}$?

$\sigma = \tau_{1} \dots \tau_{n}$ con $n = 2t$ e $\tau_i$ una trasposizione. L'inverso di una trasposizione \`e se stessa, ossia $\tau^{-1} = \tau$, quindi:
\[
\sigma^{-1} = \tau_n \dots \tau_1
\]
$A_n$ \`e quindi un sottogruppo di $S_n$ e si chiama gruppo alterno di ordine \label{gruppo_alterno} $n$.

L'insieme delle permutazioni dispari non \`e un sottogruppo di $S_n$ perch\'e il prodotto di due permutazioni dispari \`e una permutazione pari.

Il numero delle permutazioni dispari \`e uguale al numero delle permutazioni pari.
\[
|A_n| = \frac{n!}{2}
\]
\textbf{Esercizio:} trovare la corrispondenza biunivoca fra le permutazioni pari e le permutazioni dispari.

Trovare $F : A_n \to P_n$ e $F^{-1} : P_n \to A_n$, con $P_n$ ad indicare l'insieme delle permutazioni dispari.

Come conseguenza abbiamo quanto detto sopra, ossia siccome la cardinalit\`a dell'insieme delle permutazioni ha cardinalit\`a $n!$ la cardinalit\`a di $A_n$ \`e $\frac{n!}{2}$

L'indice di $A_n$ \`e:
\[
\frac{|S_n|}{A_n} = 2
\]
$A_n$ \`e un sottogruppo normale.

$A_n$ \`e il nucleo del morfismo $f : S_n \to \mathbb{Z}_2$:
\[
f (\sigma) = 
\begin{cases}
0 \text{ se } \sigma \text{ \`e pari} \\
1 \text{ se } \sigma \text{ \`e dispari} 
\end{cases}
\]
\`E un morfismo perch\'e 1 per 1 va in 0 e 0 per 0 va in 0, ossia una permutazione pari per una pari va in una pari, e una permutazione dispari per una dispari va in una pari.

% SONO ARRIVATO QUI A SISTEMARE

A_n = gruppo alterno su n elementi. \`E un sottogruppo di S_n.

|A_n| = \frac{n!}{2}

Esercizio: dimostrarlo

|S_n| = n!

A_n \`e il gruppo di permutazioni pari, ossia l'insieme di permutazioni esprimibili come il prodotto di un numero pari di trasposizioni.

Una trasposizione ha \textit{un} ciclo di lunghezza 2 e tutti gli altri di lunghezza 1.

D_n = insieme delle permutazioni dispari.

C'\`e una biezione F : A_n \to D_n

\forall \sigma \in A_n F(\sigma), come la definisco la biezione?

Prendiamo [n] - \{ 1 \dots n \} sui primi n numeri naturali. \sigma \`e una permutazione pari sui primi n numeri naturali. Per rendere \sigma dispari, la moltiplico per un'altra trasposizione.

F(\sigma) = (1 2) \cdot \sigma \in D_n

F \`e biunivoca. Deve esistere F^{-1} : D_n \to A_n

D_n(\sigma) = (1 2) \cdot \sigma

(F F^{-1}) (\delta) = F((1 2) \delta) = (1 2) \cdot (1 2) \delta = \delta

(F^{-1} F) (\sigma) = F^{-1}((1 2) \sigma) = (1 2) \cdot (1 2) \cdot \sigma = \sigma

Esercizio 2: ogni permutazione si esprime come prodotto di trasposizioni.

Prendiamo una permutazione \sigma. Abbiamo dimostrato che le permutazioni si possono esprimere come prodotto di cicli.

\sigma = \mu_1 \cdot \mu_2 \dots \mu_t

\sigma \`e il prodotto di t permutazioni. Ciascuna \mu_i \`e una permutazione k_i-ciclica, ossia \mu_i ha un solo ciclo di lunghezza i, tutti gli altri cicli sono di lunghezza 1.

1 2 3 4 5 6 7
2 4 1 3 6 5 7

(1 2 4 3) (5 6) = \mu_1 \cdot \mu_2

\mu_1 = (1 2 4 3)

\mu_2 = (5 6)

Quindi basta dimostrare che ogni permutazione k ciclica si pu\`o esprimere come un prodotto di trasposizioni.

Per scrivere una permutazione k ciclica come prodotto di trasposizioni, accoppio gli elementi a due a due.

(1 2 4 3) = (1 2) (2 4) (4 3)

1 2 3 4 5 6 7
1 2 4 3 5 6 7
1 4 2 3 5 6 7
2 4 1 3 5 6 7

L'ordine \`e l'ordine di composizione delle funzioni.

Quindi, dato un ciclo \mu_i = a_1 \dots a_t, lo scrivo come prodotto di trasposizioni:

\mu_i = (a_1 a_2) (a_2 a_3) \dots (a_{t-1} a_t)

Quindi ogni permutazione k_i-ciclica ha parit\`a uguale alla parit\`a di k_i - 1.

Quindi la parit\`a di \sigma = \mu_1 \cdot \mu_2 \dots \mu_t \`e:

\sum_{i = 1}^{t} (k_i - 1) = t + \sum_{i = 1}^{t} k_i

L'ordine di una permutazione \sigma \`e la cardinalit\`a del sottogruppo generato da \sigma, < \sigma >, ossia tutte le potenze di \sigma. Se prendo una permutazione \mu k-ciclica, l'ordine di \mu \`e k.

Una trasposizione ha ordine 2. < (5 6) > = \{ 1, (5 6) \}

Il sottogruppo generato da < (1 2 4 3) > = \{ 1, (1 2 4 3), (1 4) (2 3), (1 3 4 2) \}

(1 2 4 3)^2
1 2 3 4
2 4 1 3
4 3 2 1

Quindi (1 2 4 3)^2 = (1 4) (2 3)

(1 2 4 3)^2
1 2 3 4
2 4 1 3
4 3 2 1
3 1 4 2

Quindi (1 2 4 3)^3 = (1 3 4 2)

k \`e quindi \inf (t : \sigma^t = 1 con t \neq 0), \`e il pi\`u piccolo intero t per cui \sigma^t \`e l'identit\`a.

Se in generale \sigma \`e il prodotto di \mu_1 \dots \mu_t, l'ordine di \sigma \`e il mcm delle lunghezze dell'ordine dei suoi cicli.

\sigma^j = \mu_1^j \dots \mu_t^j = 1

< \sigma > = \{ \sigma^0, \sigma^1 \dots \sigma^j \}

j deve essere il mcm delle lunghezze di ciascun \mu_i

Esercizio:

H = \{ \sigma \in S_4 t.c. \sigma = 1 oppure \sigma \`e il prodotto di trasposizioni disgiunte \}. H \`e un sottogruppo di S_4?

H = \{ 1, (1 2) (3 4), (1 3) (2 4), (1 4) (2 3) \}

H contiene l'unit\`a, quindi verifica una delle propriet\`a. Verifichiamo se, data una permutazione \sigma, H deve contenere \sigma^{-1}. \`E verificato perch\'e l'inverso di un elemento \`e l'elemento stesso.

In generale l'inverso di un prodotto in un gruppo non commutativo \`e il prodotto al contrario degli inversi. Ma in questo caso sono commutativi i singoli elementi, quindi:

\sigma^{-1} = ((1 2) (3 4) )^{-1} = (3 4)^{-1} (1 2)^{-1} = (4 3) (2 1) = (1 2) (3 4)

Si chiama idempotenza.

\sigma_1 \sigma_2 = \sigma_3 = \sigma_2 \sigma_1

\sigma_1 \sigma_3 = \sigma_1 = \sigma_3 \sigma_1

\sigma_2 \sigma_3 = \sigma_2 = \sigma_3 \sigma_2

Proviamolo con \sigma_1 \sigma_2:

\sigma_1 \sigma_2
1 2 3 4
3 4 1 2
4 3 2 1

(1 4) (2 3)

H \`e un sottogruppo commutativo di un gruppo non commutativo.

L'ordine di H \`e 4. L'ordine di S_4 \`e 4! S_4 pu\`o avere sottogruppi di ordine che divide l'ordine di S_4.

I sottogruppi di H (diversi da H e dall'unit\`a) devono avere ordine 2. I sottogruppi di ordine 2 sono 3: < \sigma_1 > = \{ 1, \sigma_1\}, < \sigma_2 > = \{1, \sigma_2\}, < \sigma_3 > = \{1, \sigma_3 \}.

Se esprimo una \sigma come prodotto di cicli, il prodotto dei cicli \`e commutativo perch\'e i cicli sono disgiunti. Le permutazioni cicliche con elementi in comune non sono commutative.

Esercizio:
Determinare un elemento x di S_8 tale che a x a = a c b a b

Dove a = (1 2 3) (2 3 4) (4 5 6)
non \`e un prodotto di cicli.

b = 
1 2 3 4 5 6 7 8
2 1 5 4 3 7 6 8
dal punto di vista dell'occupazione

c = (2 8)
\`e una trasposizione.

Determinare l'ordine di x, la sua parit\`a e una decomposizione in cicli disgiunti.

Per determinare x dobbiamo fare:

a^{-1} a x a a^{-1} = a^{-1} a c b a b a^{-1}
x = c b a b a^{-1}

% SONO ARRIVATO QUI A SCRIVERE

\section{Strutture algebriche con due operazioni}

\begin{description}
    \item[Anelli] un anello \`e una struttura algebrica $(A, +, \cdot)$ t.c. 
    \begin{enumerate}
        \item La prima operazione $\left( A, + \right )$ \`e un gruppo abeliano.
        \item La seconda operazione considerata sull'insieme escluso l'elemento neutro, $(A \setminus \left \{ 0 \right \}, \cdot )$ \`e un semigruppo.
        \item $ \forall a, b, c \in A , \ a \cdot (b + c) = a \cdot b + a \cdot c $
        \item $ \forall a, b, c \in A , \ (a + b) \cdot c = a \cdot c + b \cdot c $
    \end{enumerate}
    \item[Campi] \`e un anello in cui $( A \setminus \left \{ 0 \right \}, \cdot )$ \`e un gruppo abeliano.
\end{description}

Gli interi sono un anello: $\left ( \mathbb{Z}, +, \cdot \right )$.

I razionali sono un campo: $\left ( \mathbb{Q}, +, \cdot \right )$. Anche $\mathbb{R}$ e $\mathbb{C}$ sono un campo.

% SONO ARRIVATO QUI A SISTEMARE

\subsection{Anelli}

un anello \`e una struttura algebrica con 2 operazioni (A, +, \cdot) tale che:

\begin{description}
    \item[1A] (A, +) \`e un gruppo abeliano (ossia un gruppo commutativo)
    \item[2A] (A, \cdot) \`e un semigruppo, ossia una struttura algebrica associativa
    \item[3A] valgono le propriet\`a distributive (devo scriverle entrambe perch\'e non \`e detto che le operazioni siano associative)

    \forall a b c \in A a (b + c) = ab + ac, (b + c) a = b a + c a
\end{description}

Se l'anello \`e un monoide rispetto al prodotto (ossia ha l'unit\`a), si chiama anello unitario.

Anello unitario \Rightarrow (A, \cdot) \`e un monoide.

Anello commutativo \Rightarrow (A, \cdot) \`e una struttura commutativa.

Anello privo di divisori dello 0, con 0 a indicare l'unit\`a di (A, +). Se a \cdot b = 0 allora a = 0 oppure b = 0 (oppure non esclusivo).

(\mathbb{Z}, +, \cdot) \`e un anello commutativo unitario privo di divisori dello 0.

Prendiamo tutte le funzioni R^R rispetto a + e a \cdot (R^R, +, \cdot)

(f + g) : R \to R \`e definita come (f + g) x = f(x) + g(x) 

(f \cdot g) : R \to R \`e definita in modo naturale anche questa come (f \cdot g) (x) = f(x) \cdot g(x)

Questo \`e un anello. Lo 0 di questo anello rispetto a (R^R, +) \`e \underline{0} : R \to R con \underline{0} + f = f = f + \underline{0}.

\underline{0} (x) = 0

1 : R \to R

1(x) = 1

Ha divisori dello 0. Ne facciamo un esempio, trovarne altri.

f : R \to R
f(x) =
\begin{cases}
x se x = 2n \\
0 altrimenti
\end{cases}

f \neq \underline{0}

Prendiamo una g : R \to R definita cos\`i:

g(x) =
\begin{cases}
x se x = 2n + 1 \\
0 altrimenti
\end{cases}
Anche g \neq \underline{0}

ma (f \cdot g) (x) = 0 \forall x \in X

Quindi f \cdot g = \underline{0}. Abbiamo trovato due elementi del gruppo (R^R, \cdot) il cui prodotto da \underline{0} anche se sono entrambi diversi da \underline{0}.

f e g sono due divisori dello 0.

Teorema di divisione

Dato a \in Z e n > 0 con n \in N, allora esistono due numero q, r \in Z tali che
\begin{description}
    \item a = n \cdot q + r
    \item 0 \le r < n
\end{description}
La coppia q, r \`e unica. Ossia se (q', r') soddisfa 1 e 2, allora q = q' e r = r'.

Facciamo questa dimostrazione usando il principio del buon ordinamento di N. Tutti i sottoinsiemi di N diversi dal vuoto hanno un primo elemento.

n \ge 2

Indichiamo con M = \{ m \in N tali che m = a - n \cdot q con q \in Z \}

Il resto r \`e uno degli elementi di M, in particolare il pi\`u piccolo. M \neq \emptyset, perch\'e se a > 0 \Rightarrow a \in M. Se invece a \le 0 \Rightarrow possiamo fare un piccolo trucchetto. a - n \cdot q = - a \cdot (-1 + n \cdot q) e pongo q = a,

a - n \cdot a = - a \cdot (-1 + n \cdot a)

a - n \cdot a \`e positivo, quindi - a \cdot (-1 + n a) \in M

Siccome M \`e diverso dal vuoto e \`e sottoinsieme di N
M \subseteq N
segue per il principio del buon ordinamento che M ha un primo elemento r (il pi\`u piccolo).

Quindi r = a - n q \Rightarrow a = n q + r.

Dobbiamo dimostrare la seconda propriet\`a, ossia che 0 \le r < n

Supponiamo per assurdo che n \le r \Rightarrow r = n + x con x \le r. Siccome a = n q + r, a = n q + (n + x) = n (q + 1) + x \Rightarrow x \in M e minore di r, quindi ho l'assurdo: r \`e il pi\`u piccolo elemento di M.

Se voglio fare il teorema di divisione con un numero qualunque?

Possiamo esprimere il teorema generale di divisione:

a, b \in Z con b \neq 0 allora \exist q, r \in Z tali che a = q b + r e 0 \le r < |b|. La coppia q, r \`e unica anche in questo caso. Segue come conseguenza dal teorema precedente. 

mcm(a,b) = m 
\Leftrightarrow
\begin{cases}
m \ge 0 
m = k a
m = h b
\`e il sup di a e b nel reticolo della divisibilit\`a: z = k' a e z = h' b \Rightarrow m \le z
\end{cases}

MCD(a,b) = d
\Leftrightarrow
\begin{cases}
d \ge 0
d | a (divide)
d | b
d' | a e d' | b \Rightarrow d' \le d
Quindi d \`e l'inf di a e b nel reticolo di cui sopra.
\end{cases}

Esistenza del minimo comune multiplo. Esiste per il principio del buon ordinamento.

M = \{ t \in N tali che t = k a e t = h b \}, M \`e non vuoto e ha un primo elementi, e quindi esiste il mcm.

Perch\'e \`e non vuoto? Perch\'e a \cdot b \in M. mcm(a,b) \`e il pi\`u piccolo elemento di M.

La dimostrazione per il MCD \`e pi\`u lunga.

Dati a, b \in \mathbb{Z} con b \neq 0, MCD(a, b) = MCD(|a|, |b|)

Esistenza del MCD(a, b). Supponiamo a > 0, b > 0.

Consideriamo l'insieme S_{a, b} = \{ n \in \mathbb{N}^{\ast} : n = a \cdot x + b \cdot y con x, y \in \mathbb{Z}\}, ossia n \`e combinazione lineare di a e b. x ed y sono i coefficienti della combinazione. \mathbb{N}^{\ast} = \mathbb{N} \setminus \{ 0 \}.

S_{a, b} \neq \emptyset, infatti a+b, a, b sono tutti \in S_{a,b}.

S_{a,b} ha un minimo d = MCD(a,b). Bisogna dimostrare che:
\begin{itemize}
    \item d | a e d | b
    \item z | a e z | b \Rightarrow z | d, ossia d \`e il \sup(a,b) nel reticolo (\mathbb{N}, |)
\end{itemize}
\begin{proof}
Tesi: d | a, con d = s \cdot a + t \cdot b come ipotesi, inoltre d \`e il minimo di S_{a,b}. Dobbiamo dimostrare che a = q \cdot d + r con r = 0 \Rightarrow r = a - q \cdot d \Rightarrow r = a - q \cdot (s \cdot a + t \cdot b) = a - q \cdot s \cdot a - q \cdot t \cdot b = a \cdot (1 - q \cdot s) + b \cdot (- q \cdot t)

Sappiamo che per il teorema di divisione su \mathbb{Z}, 0 \le r < d. r \`e una combinazione lineare di a, b, quindi r \in S_{a,b} se r \neq 0. Ma r deve essere pi\`u piccolo di d, quindi non pu\`o appartenere a S_{a,b} essendo d il minimo di S_{a,b}. Quindi r \`e necessariamente 0.
\end{proof}
\begin{proof}
Ipotesi: z | a e z | b. Tesi z < d quindi z | d.

a = z \cdot k e b = z \cdot h. Sapendo che d = s \cdot a + b \cdot t, posso sostituire e ottenere d = s \cdot z \cdot k + t \cdot z \cdot h, quindi d = z \cdot ( s \cdot k + t \cdot h), quindi d \`e un multiplo di z.
\end{proof}

Il MCD si calcola con l'algoritmo di Euclide delle divisioni successive.

\begin{lem}
Siano a > b > 0, allora posto d = MCD(a,b) e d' = MCD(b, r) dove a = q \cdot b + r, allora d = d'.
\end{lem}
\begin{proof}
Tesi: d | d' e d' | d, e quindi sono uguali.

d | a, d | b \Rightarrow d | ( b \cdot q + r ), ma siccome d | b , se divide la somma divide gli addendi, quindi d | r \Rightarrow d | r, d | b \Rightarrow d | d' ossia d < d'. \`E pi\`u piccolo del MCD(b, r), poich\'e divide entrambi.

d' | b, d' | r \Rightarrow d' | a = q \cdot b + r \Rightarrow d' | a, d' | b \Rightarrow d' | d
\end{proof}
Su questo lemma si basa l'algoritmo di Euclide.

Algoritmo:

a > b > 0

1 a = b \cdot q_1 + r_1  con 0 \le r_1 < b, se r_1 = 0 ho trovato il MCD(a,b) = b, altrimenti continuo
2 b = r_1 \cdot q_2 + r_2  con 0 \le r_2 < r_1, se r_2 = 0 ho trovato il MCD(a,b) = r_1, ossia l'ultimo resto non nullo, altrimenti continuo
3 r_1 = r_2 \cdot q_3 + r_3 ... il MCD(a,b) \`e l'ultimo resto non 0

Poich\'e 0 \le r_{(i+1)} < r_i, \exists n > 0 t.c. r_{n} \neq 0 e r{(n+1)} = 0. Quindi al passo n-esimo avr\`o:

n r_{(n-2)} = r{(n-1)} \cdot q_n + r_n
(n+1) r_{(n+1)} = q_{(n+1)} \cdot r_n + 0

Per il lemma sopra segue che MCD(a,b) = MCD(r_{(n-1)}, r_{n}) = r_{n}.

Possiamo ricavere l'identit\`a di B\'ezouf

d = MCD(a,b), quindi posso scriverlo come d = a \cdot s + b \cdot t con s, t \in \mathbb{Z}. L'identit\`a di B\'ezouf sono infinite.

Possiamo scrivere d = a \cdot s + b \cdot t prendendo (s + k \cdot b, t - k \cdot a) e fare la combinazione lineare con questi coefficienti:

a (s + k \cdot b) + b \cdot (t - k \cdot a) = a \cdot s + k \cdot b \cdot a + b \cdot t - k \cdot a \cdot b = d

Dimostrarlo per esercizio.

Scriviamo ogni volta il resto in funzione di a e b.

MCD(159, 42)

159 > 42
1. 159 = 43 (3) + 33     33 = 159 - 42 (3)
2. 42 = 33 (1) + 9       9 = 42 - 33
3. 33 = 9 (3) + 6        6 = 33 - 9 (3)
4. 9 = 6 + 3             3 = 9 - 6
5. 6 = 3 (2)

MCD(159, 42) = 3

Vogliamo ora trovare l'identit\`a di B\'ezouf per 3.

Possiamo scrivere 3 = 9 - 6

Sostituiamo via via i resti.

3 = 9 - 6 = 9 - 33 + 9 (3) = 9 (4) - 33 = 42 (4) - 33 (4) - 33 = 42 (4) - 33 (5) = 42 (4) - 159 (5) + 42 (15) = 42 (19) - 159 (5)

Dati a, b \in \mathbb{Z}, a e b si dicono coprimi tra loro se MCD(a,b) = 1

p \in \mathbb{N} si dice primo se p \neq 1 e \`e divisibile solo per 1 e per p.

(\mathbb{Z}, +, \cdot) \`e un anello commutativo unitario privo di divisori dello zero.

Per costruire \mathbb{Z} abbiamo preso \mathbb{N}, costruito \mathbb{N} \times \mathbb{N}, abbiamo considerato il monoide (\mathbb{N}, +) e creato il monoide (\mathbb{N} \times \mathbb{N}, +). Se prendo una struttura algebrica e faccio il prodotto ottengo una struttura algebrica che mantiene le stesse operazioni e le stesse propriet\`a.

Definisco adesso + : (\mathbb{N} \times \mathbb{N}) \times (\mathbb{N} \times \mathbb{N}) \to \mathbb{N} \times \mathbb{N} come (a,b), (c,d) \mapsto (a,b) + (c,d) = (a + c, b + d)

Per ottenere \mathbb{Z} si fa una relazione di equivalenza su \mathbb{N} \times \mathbb{N}, \rho, che \`e una congruenza rispetto a +.

(\mathbb{N} \times \mathbb{N} / \rho, +) \`e un monoide perch\'e \rho \`e una congruenza. 

(a,b) \ \rho \ (c,d) \Leftrightarrow a + d = b + c, ossia a - b = c - d.

Esercizio: dimostrare che \rho \`e una congruenza.


\mathbb{N} \times \mathbb{N} / \simequiv \mathbb{R}, ossia \`e in corrispondenza biunivoca.

[(m,n)] = 
\begin{cases}
[(m,0)] = +m
[(0,0)] = \underline{0}
[(0,m)] = -m
\end{cases}

Non \`e solo un monoide: \`e un gruppo, perch\'e ha l'inverso. [(m, 0)] + [(0, m)] = [(m, m)] = [(0,0)]

\mathbb{Z} ha un'altra operazione, \cdot, che potrei pensare dipendere da (\mathbb{N}, \cdot), ma \rho non \`e una congruenza rispetto a (\mathbb{N} \times \mathbb{N}, \cdot).

\cdot : (\mathbb{N} \times \mathbb{N}) \times (\mathbb{N} \times \mathbb{N}) \to \mathbb{N} \times \mathbb{N} tale che (a, b) \cdot (c, d) = (a \cdot c, b \cdot d) \textit{non \`e} una congruenza. Scelgo quindi un'altra operazione \cdot su \mathbb{N} \times \mathbb{N}.

Vediamo intanto che \rho non \`e una congruenza rispetto a \cdot.

Basta un controesempio: (3, 0) \cdot (2, 0) = (6, 0). Prendiamo ora un elemento nella classe [(3,0)], ad esempio (6,3), ed un elemento nella classe [(2,0)], ad esempio (4,2). Il loro prodotto (6,3) \cdot (4,2) = (24,6) \in [(18,0)] \neq [(6,0)].

Per ottenere quindi una congruenza in \mathbb{Z} devo prendere un'altra moltiplicazione in \mathbb{N} \times \mathbb{N}.

(\mathbb{N} \times \mathbb{N}, +, \cdot). + lo prendo direttamente da (\mathbb{N}, +), mentre \cdot lo prendo come

Se definisco la congruenza come (m, n) \ \rho \ (p, q) \Leftrightarrow m \cdot q = n \cdot p.

Quindi (m - n) (p - q) = m p - n p + n q - m q = m p + n q - ( n p + m q)

Se voglio esprimere questo intero m p + n q - ( n p + m q) in \mathbb{N} \times \mathbb{N}, come devo esprimerlo? Che coppia deve darmi?

(m, n) \cdot (p, q) \in [((m p + n q), (n p + m q))]

Fissato un interno n \ge 2, abbiamo definito la congruenza \equiv_n (congruenza modulo n) come

a, b \in \mathbb{Z}, a \equiv_n b \Leftrightarrow n | (a - b)

\`E una congruenza rispetto a entrambe le operazioni.

(\mathbb{Z} / \equiv_n, +, \cdot) \`e un anello commutativo e unitario. Non \`e privo di divisori dello zero.

\mathbb{Z} / \equiv_2 = \{ [0], [1] \}

Ogni classe [a] \in \mathbb{Z} / \equiv_n pu\`o essere rappresentato con il suo resto, ossia [a] = [r] dove r \`e il resto nella divisione di a per n.

Possiamo considerare \mathbb{Z}_n come l'insieme dei resti delle possibili divisioni. \mathbb{Z}_n = \{ 0, 1 \dots (n-1)\}

\varphi_n : Z / \equiv_n \to Z_n che associa ad ogni classe il resto della divisione, ossia \varphi_n [a] = r

(\mathbb{Z}_n, +, \cdot ) \`e un anello.

\mathbb{Z}_3 = \{ [0], [1], [2] \} \leftrightarrow \mathbb{Z}_3 = \{ 0, 1, 2 \}

Se il gruppo \`e finito possiamo scrivere le tavole di composizione rispetto alle operazioni.

\begin{tabular}{c|ccc}
+ & 0 & 1 & 2 \\
\hline
0 & 0 & 1 & 2 \\
1 & 1 & 2 & 0 \\
2 & 2 & 0 & 1
\end{tabular}

\begin{tabular}{c|ccc}
\cdot & 0 & 1 & 2 \\
\hline
0 & 0 & 0 & 0 \\
1 & 0 & 1 & 2 \\
2 & 0 & 2 & 1
\end{tabular}

Quando l'operazione \`e commutativa, la tavola \`e uguale rispetto alla diagonale (\`e simmetrica).

(\mathbb{Z}_3, +, \cdot) \`e sempre un anello commutativo unitario. Ha l'unit\`a rispetto al \cdot, ossia 1.

\begin{tabular}{c|cccc}
+ & 0 & 1 & 2 & 3 \\
\hline
0 & 0 & 1 & 2 & 3 \\
1 & 1 & 2 & 3 & 0 \\
2 & 2 & 3 & 0 & 1 \\
3 & 3 & 0 & 1 & 2
\end{tabular}

\begin{tabular}{c|cccc}
\cdot & 0 & 1 & 2 & 3 \\
\hline
0 & 0 & 0 & 0 & 0 \\
1 & 0 & 1 & 2 & 3 \\
2 & 0 & 2 & 0 & 2 \\
3 & 0 & 3 & 2 & 1
\end{tabular}

Sia (A, +, \cdot) un anello unitario (monoide associativo rispetto a \cdot), U(A) \`e il gruppo degli elementi invertibili di A rispetto a \cdot.

U(\mathbb{Z}) = \{ -1, 1 \}

U(\mathbb{Z}_2) = \{ 1 \}

U(\mathbb{Z}_3) = \{ 1,  2 \}

Vogliamo capire come \`e fatto in generale il gruppo degli elementi invertibili in \mathbb{Z}_n.

\begin{prop}
[a] \in U(\mathbb{Z} / \equiv_n) \Leftrightarrow a, n sono coprimi, ossia MCD(a, n) = 1
\end{prop}

\begin{cor}
U(\mathbb{Z}_n) = \{ x \in \mathbb{N} : 0 < x < n e MCD(n, x) = 1\}
\end{cor}

Z_p con p primo U(Z_p) = \{ 1 \dots (p-1)\}, ossia sono tutti quanti.

U(Z_4) = \{1, 3\}

Ipotesi: classe [a] invertibile in Z / \equiv_n \Rightarrow \exists [b] t.c. [a] \cdot [b] = [1]. 

Quindi per definizione [a \cdot b] = [a] \cdot [b] = [1]. Quindi a e b nella divisione per n hanno lo stesso resto, ossia 1, quindi a \cdot b = n \cdot q + 1, e per il teorema di B\'ezouf a \cdot b - n \cdot q = 1, ossia 1 \in S_{a, n}, ossia 1 \`e combinazione lineare di a e n. Quindi il MCD(a, n) = 1, quindi a e n sono coprimi.

Dobbiamo dimostrare il viceversa, ossia MCD(a, n) = 1 \Rightarrow [a] \`e invertibile in \mathbb{Z} / \equiv_n.

Quindi 1 \`e combinazione lineare di a e n, ossia 1 = a \cdot s + n \cdot t. Quindi passando alle classi, [1] = [a \cdot s + n \cdot t] = [a \cdot s] + [n \cdot t] = [a] \cdot [s] + [0] = [a] \cdot [s], quindi la classe rappresentata da s \`e l'inverso della classe rappresentata da a, perch\'e [a] \cdot [s] = [1].

Grazie all'identit\`a di B\'ezouf possiamo trovare l'inverso di una classe.

[s] = [a]^{-1}

Se prendiamo Z_p con p primo, U(Z_p) = Z_p - \{ 0 \}, ed \`e un gruppo, quindi (Z_p, +, \cdot) \`e un campo, ossia \`e una struttura algebrica con due operazioni.

Un campo \`e una struttura algebrica (K, +, \cdot) tale che:
\begin{itemize}
    \item (K, +, \cdot) \`e un anello commutativo unitario
    \item (K - \{0\}, \cdot) \`e un gruppo commutativo
\end{itemize}
Inoltre valgono le leggi distributive.

I campi non hanno divisori dello zero, ma gli anelli (Z_n, +, \cdot) hanno divisori dello zero. Infatti posso scrivere n = a \cdot b, siccome n non \`e primo, quindi la classe [0] = [a \cdot b] = [a] \cdot [b] entrambi diversi da 0. Due classi moltiplicate fanno la classe [0], quindi sono due divisori dello [0].

Il campo (Z_p, +, \cdot) non ha divisori dello 0. Sia a \cdot  b = 0 con a \neq 0 e b \neq 0, avendo l'inverso per ogni elemento diverso da 0 avrei che a^{-1} \cdot a \cdot b = a^{-1} \cdot 0 = 0 \Rightarrow b = 0 ma sarebbe un assurdo.

\begin{thm}[Teorema (fondamentale)]
[a] \in Z / \equiv_n, questa classe \`e invertibile \Leftrightarrow MCD(a, n) = 1, ossia se sono coprimi.
\end{thm}

Da questo teorema possiamo dedurre due corollari.

\begin{cor}\label{corollario_interi_primo}
Z_p = \{ 0, 1 \dots (p-1) \}, ossia l'anello dei resti modulo p, \`e un campo \Leftrightarrow p \`e un numero primo, ossia p \`e maggiore di 1 ed \`e divisibile solamente per 1 e per p.

Essere un campo significa che (Z_p \setminus \{ 0 \}, \cdot) con la moltiplicazione \`e un gruppo abeliano.
\end{cor}

\begin{cor}\label{corollario_interi_secondo}
p primo, p | a \cdot b \Rightarrow p | a oppure p | b
\end{cor}
\begin{proof}
Consideriamo il campo (Z_p, +, \cdot). Se p | a \cdot b, significa che [p] = [0] = [a \cdot b] = [a] \cdot [b]. Siamo in un campo, che non ha divisori dello zero. Quindi [a] = [0] oppure [b] = [0].
\end{proof}

\begin{prop}
Ogni numero naturale n \in N maggiore di 1, o \`e primo o \`e prodotto di primi.
\end{prop}
\begin{proof}
Si dimostra per induzione su n. Per n = 2 \`e vero.

Ipotesi di induzione: P(m) \`e vera \forall m \ge 2 con m < n. Dobbiamo dimostrare che P(n) \`e vera. O n \`e primo, e ho verificato P(n), oppure n non \`e primo, ossia n = a \cdot b con a < n e b < n. Per ipotesi di induzione P(a) e P(b) sono vere, quindi a \`e prodotto di primi o \`e primo, b \`e prodotto di primi o \`e primo, quindi n \`e prodotto di primi.
\end{proof}

\begin{thm}[Teorema fondamentale dell'aritmetica]
Ogni numero naturale n \ge 2 si esprime in un unico modo come prodotto di potenze di numeri primi, ossia n ha una sola fattorizzazione.

Ossia, n = p_{1}^{h_1} \dots p_{k}^{h^k} = q_{1}^{t_1} \dots q_{s}^{t_s} \Rightarrow k = s e \forall i \in [1, k] \exists j t.c. p_i^{h_i} = q_j^{t_j}.
\end{thm}
\begin{proof}
Si dimostra per induzione. Per n = 2 \`e vero.

Supponiamo come ipotesi induttiva che P(m) sia vero per ogni 2 \le m < n. Per induzione dimostriamo che P(n) \`e vera.

n = p_{1}^{h_1} \dots p_{k}^{h^k} = q_{1}^{t_1} \dots q_{s}^{t_s}

p_1 divide n, quindi divide q_{1}^{t_1} \dots q_{s}^{t_s}

p_1 | n = q_{1}^{t_1} \dots q_{s}^{t_s}

Per il corollario \ref{corollario_interi_secondo} \exists j = 1 \dots s t.c. p_1 | q_j. Ma posso ripetere lo stesso discorso per q_j.

Per il corollario \ref{corollario_interi_primo} q_j divide n, quindi q_j | n = p_{1}^{h_1} \dots p_{k}^{h^k}. Deve esistere un indice i_j tale che q_j | p_{i_j}.

p_1 | q_j | p_{i_j} \Rightarrow p_1 = q_j = p_{i_j} essendo tutti primi.

Essendo p_1 e q_j uguali, se divido n per p_1 ottengo due scomposizioni:

\frac{n}{p_1} = p_{1}^{h_1 - 1} \dots p_{k}^{h^k} = q_{1}^{t_1} \dots q_{j}^{t_j - 1}\dots q_{s}^{t_s}

Sia m = \frac{n}{p_1} < n \Rightarrow P(\frac{n}{p_1}) \`e vera per ipotesi \Rightarrow P(n) \`e vera.

Infatti per P( \frac{n}{p_1}) k = s e \forall i = 1 \dots k \exists r tale che p_i^{h_i} = q_r^{t_r}
\end{proof}

Da questo segue:
\begin{thm}
I numeri primi sono infiniti.
\end{thm}
\begin{proof}
Supponiamo per assurdo che i numeri primi siano finiti. Abbiamo la lista di numeri primi p_1 \dots p_N. Consideriamo n = (p_1 \dots p_N) + 1. Non pu\`o essere un numero primo, perch\'e non \`e nella lista. Per il teorema fondamentale deve essere il prodotto di numeri primi.

p_i | n = (p_1 \dots p_i \dots p_N) + 1 \Rightarrow p_i | (p_1 \dots p_i \dots p_N) e p_i | 1, che \`e l'assurdo.
\end{proof}

(Z_n, +, \cdot) \`e un anello. Se n \`e primo, \`e un campo, quindi non ha divisori dello zero.

Se n = a \cdot b con a < n e b < n, allora (Z_n, +, \cdot) \`e un anello con divisori dello zero.

Sia U(A) = gruppo degli elementi invertibili dell'anello A. Considerando il campo (Z_p, +, \cdot) il gruppo degli invertibili U(Z_p) = \{1, \dots,  p-1\}, quindi la cardinalit\`a |U(Z_p)| = p-1.

Vogliamo conoscere la cardinalit\`a di U(Z_n) nel caso generale.

Consideriamo la funzione \Phi : N^+ \to N^+ definita come \Phi (n) = numero degli interi minori di n e primi con n. |U(Z_n)| = \Phi(n). Infatti avevamo definito U(Z_n) come:
\[
U(Z_n) = \{ m \in Z_n : MCD(m, n) = 1 \}
\]
Calcoliamo questa funzione (detta funzione di Eulero). Il suo valore si trova con il principio di inclusione ed esclusione.

Sia n = p_{1}^{h_1} \dots p_{k}^{h_k}, se voglio conoscere \Phi(n), so che sono n meno tutti i numeri che dividono n. Chiamo D l'insieme dei numeri m < n che dividono n.
\[
\Phi(n) = n - D
\]
D si calcola con il principio di inclusione ed esclusione. 

Indichiamo con A_{p_i} = \{ m \in [n] : p_i | m \}, D = \bigcup_{i = 1}^{k} A_{p_i}. Quindi:
\[
|\bigcup_{i = 1}^{k} A_{p_i}| = \sum_{i = 1}^{k} |A_{p_i}| - \sum |A_{p_i} \cap A_{p_j}| + \sum |A_{p_i} \cap A_{p_j} \cap A_{p_k}| \dots (-1)^{k-1} |A_{p_i} \cap \dots A_{p_k} | 
\]
Sappiamo che |A_{p_i}| = \frac{n}{p_i}. Infatti m = k \cdot p_i \Rightarrow k = \frac{m}{p_i} \`e la cardinalit\`a dell'insieme dei numeri che dividono n.

Se prendiamo l'intersezione di due insiemi? |A_{p_i} \cap A_{p_j}| con i \neq j \`e:
\[
|A_{p_i} \cap A_{p_j}| = \frac{n}{p_i \cdot p_j}
\]
L'ultima intersezione ha cardinalit\`a 1. Quindi mettendo in evidenza:
\[
\Phi (n) = n - |D| = n \cdot (1 - \frac{1}{p_1}) \dots (1 - \frac{1}{p_k})
\]
\begin{thm}[Teorema di Fermat]
Se prendo a \in Z e n \ge 2 tali che MCD(a, n) = 1, allora a^{\Phi(n)} \equiv_n 1. 
\end{thm}
\begin{proof}
L'insieme degli elementi invertibili di Z_n \`e l'insieme di tutti gli h \in Z_n tali che MCD(h, n) = 1.

U(Z_n) = \{ h \in Z_n : MCD(h, n) = 1 \}

|U(Z_n)| = \Phi(n). 

Il prodotto \prod_{h \in U(Z_n)} [h \cdot a]  per definizione del prodotto fra classi \`e = \prod_{h \in U(Z_n)} [h] \cdot [a] e mettendo in evidenza a = [a]^{\Phi(n)} \cdot \prod_{h \in U(Z_n)} [h].

Siccome il MCD(h, n) = 1 e il MCD(a, n) = 1, allora il MCD(a \cdot h, n) = 1.

Quindi \prod_{h \in U(Z_n)} [h \cdot a] = \prod_{h \in U(Z_n)} [h]

Segue che [a]^{\Phi(n)} = 1 \Rightarrow a^{\Phi(n)} \equiv_n 1.
\end{proof}

\begin{cor}[Piccolo teorema di Fermat]
Dato p primo segue che a^{p-1} \equiv_p 1.
\end{cor}

\textbf{Esercizio:} calcolare le ultime 2 cifre di 81^{82}. Le ultime due cifre sono il resto modulo 100, quindi passando alle classi dobbiamo calcolare r < 100 tale che 81^{82} \equiv_{100} r, ossia il rappresentante della classe.

Usiamo il teorema di Fermat. Calcoliamo 81^{\Phi (100)} \equiv_{100} 1. \Phi(100) = 40, possiamo quindi dire che 81^{40} \equiv_{100} 1.

Quindi: 81^{82} = 81^{80 + 2} = 81^{80} \cdot 81^{2} \equiv_{100} 1 \cdot 81^{2} = 6561 \equiv_{100} 61

\subsection{Equazioni di primo grado in Z_n}

Come \`e fatta un'equazione di primo grado in Z_n?

\begin{enumerate}
    \item se la vedo in Z_n, ho: a \cdot x = b con a, b, x \in Z_n
    \item se la vedo come quoziente, ho: [a] \cdot [x] = [b] in Z / \equiv_n
    \item se la vedo in Z, ho: a \cdot x \equiv_n b con a, b, x \in Z
\end{enumerate}

\begin{oss}
Le soluzioni di 3, se esistono, sono infinite, perch\'e se s \in Z \`e una soluzione, a \cdot s \equiv_n b. Quindi ogni altro s' \in [s] \`e tale che a \cdot s' \equiv_n b.

Passando alle classi si legge come [a \cdot s] = [b] \Rightarrow [a] c\dot [s] = [b], e prendendo [s'] = [s] anche [a] \cdot [s'] = [b]
\end{oss}

In generale si distinguono due casi:
\begin{enumerate}
    \item MCD(a, n) = 1 \Rightarrow [a] \`e invertibilie in Z / \equiv_n, ossia se a < n \Rightarrow a \`e invertibile in Z_n. Come si trova la soluzione?
    \begin{itemize}
        \item Nel caso (1) a \cdot x = b in Z_n, x = a^{-1} \cdot b. La soluzione \`e unica.
        \item Nel caso (2) [a] \cdot [x] = [b], allora la soluzione [x] = [a]^{-1} \cdot [b]. La soluzione \`e unica.
        \item Nel caso (3) le soluzioni sono infinite e sono tutte congruenti a x modulo n.
    \end{itemize}
    \item MCD(a, n) = d > 1
\end{enumerate}

\begin{exmp}
3 x \equiv 2 \pmod{7}. Scrivo l'identit\`a di B\'ezouf:

1 = 3 \cdot s + 7 \cdot t = 3 \cdot (-2) + t \cdot (1)

Quindi:

[3] [x] = [2] \Rightarrow [x] = [3]^{-1} [2]

[1] = [3] \cdot [-2] + [7] = [3] \cdot [-2] + [0] = [3] \cdot [-2] = [3] \cdot [5]

[-2] = -[2], qual \`e un rappresentante della classe -[2]? -[2] \`e la classe che sommata a [2] mi d\`a [7] = [0]. [5] + [2] = [7]

Quindi [x] = [5] \cdot [2] = [10] = [3]. La soluzione \`e [3]

Un altro modo, sempre partendo dall'identit\`a di B\'ezouf, \`e:

1 = 3 \cdot s + 7 \cdot t \Rightarrow 2 = 3 \cdot 2s + 14 \cdot t. Passo alle classi e ho:

[x] = [3] [2s]
\end{exmp}

a, b \in Z e a,b > 0

S_{a,b} =  \{m \in N^+ : ax + by = m con x,y \in Z \}

Questo insieme ha un minimo d = inf S_{a,b} = MCD(a,b)

Anche d si pu\`o scrivere come combinazione lineare di a e b. d \in S, d = a s + b t con s, t \in Z. Si chiama identit\`a di B\'ezouf. Le coppie s,t sono infinite.

D_{a,b} = \{ (s, t) \in Z \times Z : d = a s + b t \}

Data una coppia (s,t), come posso trovarne un'altra? (s + k b, t - k a) \in D_{a,b} al variare di k \in Z. Andando a sostituire ho che:

a (s + kb) + b(t - ka) = as + kab + bt -kba = as + bt

Per calcolare una identit\`a di B\'ezouf si usa l'algoritmo di Euclide delle divisioni successive.

\begin{prop}
S_{a,b} \`e l'insieme di tutti i multipli di d = MCD(a,b).

S_{a,b} = \{ k d : k \in N^+ con d = MCD(a,b) \}
\end{prop}
\begin{proof}
Tesi: se m = kd \Rightarrow m \in S_{a,b}.

m = k d = k (as + bt) = a (ks) + b (kt) \Rightarrow m \in S_{a,b} perch\'e possiamo prendere x = ks e y = kt.

Viceversa se m \in S_{a,b} \Rightarrow m = kd.

m = ax + by. Essendo d = MCD(a,b), ho che a = hd e b = h' d. Quindi m = hdx + h'dy = (hx + h'y) d \Rightarrow m \`e multiplo di d.
\end{proof}
Quindi l'insieme S_{a,b} \`e l'insieme dei multipli del MCD.

Teorema di Fermat:

Se MCD(a, n) = 1 \Rightarrow a^{\Phi(n)} \equiv 1 \pmod n

Il teorema di Fermat \`e un corollario del teorema di Lagrange.

Il teorema di Lagrange dice che dato un gruppo finito, l'ordine di ogni suo sottogruppo divide l'ordine del gruppo.

Dato un gruppo G finito e S sottogruppo di G, |S| | |G| (ossia la cardinalit\`a di S divide la cardinalit\`a di G).

Perch\'e \`e una conseguenza? 

\Phi(n) = | U(Z_n) | ossia la cardinalit\`a del gruppo degli elementi invertibili rispetto a \cdot dell'anello (Z_n, +, \cdot).

G = U(Z_n)

S = < a > \`e il sottogruppo generato da a, ossia tutte le potenze di a.

< a > = \{ a^0, \dots a^t \}. Ha t + 1 elementi. Quindi a^{t+1} = 1.

Esempio:
(Z_12, +, \cdot) con Z_6 = \{0,1,2,3,4,5,6,7,8,9,10,11\}

U(Z_12) = \{ a : MCD(a, 12) = 1\} = \{ 1, 5, 7, 11 \}

L'inverso di 5 \`e 5, perch\'e 5 \cdot 5 = 25 \equiv_{12} 1. L'inverso di 7 \`e 7, l'inverso di 11 \`e 11. Abbiamo tre sottogruppi non banali di ordine 2.

Prendiamo il sottogruppo S = \{ 1, 5 \}. Dire che MCD(a, n) = 1 significa che a \in U(Z_n).

L'ordine \`e il pi\`u piccolo intero positivo che mi d\`a 1. Quindi 5^2 = 1, essendo l'ordine di S = \{ 1, 5 \} pari a 2.

Siccome l'ordine |< a >| = o | \Phi(n), \Phi(n) = k \cdot o. Quindi a^{\Phi(n)} = a^{o \cdot k} = 1^k = 1.

Importante: a \in U(Z_n) \Leftrightarrow MCD(a, n) = 1

Equazioni in Z_n di primo grado

ax = b, a, b \in Z_n, x \in Z_n

\begin{enumerate}
    \item MCD(a, n) = 1. a x = b ha una sola soluzione in Z_n x = a^{-1} \cdot b. Come si trova a^{-1}? Con l'identit\`a di B\'ezouf. Siccome MCD(a,n) = 1 \Rightarrow posso scrivere l'identit\`a di B\'ezouf per a, n. 1 = a \cdot s + n \cdot t. Passo alle classi modulo n.

    [1] = [as] + [nt] = [as] + [0] = [a] [s] \Rightarrow [a^{-1}] = [s], ma poich\'e s = n q + r ho che r = a^{-1}

    1 = as + bt
    ax = b
    b = asb + ntb
    [b] = [asb] = [a] [sb] = [a] [x]

    x = r, con sb = nq + r

    \item MCD(a, n) = d > 1

    \begin{prop}
    L'equazione a x = b ha soluzione in Z_n \Leftrightarrow d | b, altrimenti \`e incompatibile (non ha soluzioni).
    \end{prop}
    \begin{proof}
    Dimostriamo che \`e condizione necessaria.

    Se a x = b \`e compatibile (ammette soluzioni) in Z_n, ossia \exists \ s \in Z_n t.c. a \cdot s = b, allora a s - b = q n, ossia \`e un multiplo di n. Quindi b = a \cdot s - q \cdot n, ossia b \in S_{a, n}. S_{a,n} sono tutti i multipli del MCD(a,n) = d \Rightarrow b = k \cdot d.

    Dimostrare che la condizione \`e sufficiente segue il percorso inverso.
    \end{proof}
    Vediamo come si calcolano le soluzioni di ax = b \in Z_n con MCD(a,n) = d > 1 e d | b.
    \begin{oss}
    MCD(a,n) = d \Leftrightarrow MCD(\frac{a}{d}, \frac{n}{d}) = 1
    \end{oss}
    Quindi se prendo:

    \frac{a}{d} x = \frac{b}{d} in Z_{\frac{n}{d}} 

    questa equazione ricade nel caso 1 e quindi ha una sola soluzione s.

    s \`e soluzione di \frac{a}{d} x = \frac{b}{d} in Z_{\frac{n}{d}} \Leftrightarrow s \`e soluzione di a \cdot x = b in Z_n.

    Non \`e molto chiaro in questo modo. Scriviamolo come congruenza.

    \frac{a}{d} x \equiv \frac{b}{d} \pmod \frac{n}{d} \Leftrightarrow s \`e soluzione a \cdot x \equiv b \pmod n

    Chiamiamo (1) la prima parte e (2) la seconda
    \begin{proof}
    Da (1) segue che:

    \frac{a}{d} s - \frac{b}{d} = q \frac{n}{d} \Rightarrow a s - b = q n \Rightarrow vale la (2).

    Viceversa basta seguire l'ordine inverso.
    \end{proof}
    [s]_{\frac{n}{d}} \`e l'unica soluzione di [\frac{a}{d}]_{\frac{n}{d}} [x]_{\frac{n}{d}} = [\frac{b}{d}]_{\frac{n}{d}}, perch\'e il MCD(\frac{a}{d}, \frac{b}{d}) = 1

    Le soluzioni di ax = b \pmod n si ripartiscono in classi di equivalenza modulo n e precisamente si ha [s]_{\frac{n}{d}} = [s]_{n} \cup [s + \frac{n}{d}]_{n} \cup \dots \cup [s + \frac{n}{d}(d-1)]_{n}

    Ci\`o significa che le soluzioni di [a] \cdot [x] = [b] in Z / \equiv_n sono $d$, e sono le d-classi di equivalenza in cui si ripartisce l'unica soluzione [s]_{\frac{n}{d}} di [\frac{a}{d}] x = [\frac{b}{d}] in Z / \equiv_{\frac{n}{d}}

    \begin{proof}
    Dimostriamo che: [s]_{\frac{n}{d}} = [s]_{n} \cup [s + \frac{n}{d}]_{n} \cup \dots \cup [s + \frac{n}{d}(d-1)]_{n}

    t \in [s]_{\frac{n}{d}} \Leftrightarrow t - s = k \frac{n}{d}

    Quindi : t = s + k \frac{n}{d}

    Bisogna solo dimostrare che k < d

    Dividiamo per d:

    k = n \cdot d + r

    Quindi t = s + (n d + r) \frac{n}{d}, e quindi
    t = s + r \frac{n}{d}, perch\'e n \cdot d \equiv 0 \pmod n

    Quindi t \in s + r \frac{n}{d} con r < d.

    Viceversa si segue l'ordine inverso.

    Dobbiamo mostrare che le classi sono disgiunte. t \in [s + r \frac{n}{d}]_{n}, dove r < d \`e il resto della divisione di k per d. Non possono esserci due resti distinti, quindi [s + r_1 \frac{n}{d}] \cap [s + r_2 \frac{n}{d}] = \emptyset, perch\'e r_1 \neq r_2 ed entrambi r_1, r_2 < d.
    \end{proof}
\end{enumerate}

\begin{exmp}[Esempio del primo caso]
3x = 11 \pmod 25

MCD(3, 25) = 1 \Rightarrow ha una sola soluzione

Scrivo l'identit\`a di B\'ezouf
1 = 3 (-8) + 25 (1) 

Moltiplico entrambi i lati per 11:
11 = 3 (-8) (11) + 25 (11)

Passo alle classi:
[11] = [3] [-8 \cdot 11] = [3] [17] [11] \Rightarrow [x] = [17] [11] = [11 \cdot 17] = [12]

In Z ha infinite soluzioni, tutti gli interi nella classe [12].

L'unica soluzione in Z_{25} \`e x = 12.

Vedendola come classi, [a] [x] = [b] in Z / \equiv_{25} l'unica soluzione \`e la classe [12] = [x].
\end{exmp}

\begin{exmp}[Esempio del secondo caso]
200 x \equiv 62 \pmod 22

Dobbiamo anzitutto verificare la compatibilit\`a dell'equazione.

MCD(200, 22) = 2

Ha soluzioni, poich\'e 2 | 62.

Consideriamo l'equazione ottenuta dividendo tutto per 2.

\frac{200}{2} x \equiv \frac{62}{2} \pmod 22 \Rightarrow 100 x \equiv 31 \pmod 11

100 x \equiv 31 \pmod 11 ha un'unica soluzione, essendo che MCD(100, 11) = 1. Troviamo l'identit\`a di B\'ezouf 1 = 100 \cdot s + 11 \cdot t.

1 = 100 (s) + 11 (t) \Rightarrow 1 = 100 (1) + 11 (-9)

La soluzione \`e la classe [1]_{11}. Va ripartita in 2 classi modulo 22.

[1]_{22} e [1 + \frac{n}{d}]_{22} = [1 + \frac{22}{2}]_{22} = [1 + 11]_{22} = [12]_{22} 
\end{exmp}





















